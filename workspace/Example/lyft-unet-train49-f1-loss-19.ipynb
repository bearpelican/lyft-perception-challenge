{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "# from fastai.dataset import *\n",
    "from fastai.models.resnet import vgg_resnet50\n",
    "\n",
    "import json\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('../data/all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(im, figsize=None, ax=None, alpha=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im, alpha=alpha)\n",
    "    ax.set_axis_off()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEHICLES=10\n",
    "ROADS=7\n",
    "ROAD_LINES=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DN = 'CameraRGB'\n",
    "MASKS_DN = 'CameraSeg'\n",
    "workers=7\n",
    "random_crop=True\n",
    "pseudo_label=False\n",
    "val_folder = 'sample_test_sync'\n",
    "# val_folder = 'val'\n",
    "S_PREFIX = '49_19'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets.folder import pil_loader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TTF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchedFilesDataset(Dataset):\n",
    "    def __init__(self, fnames, y, tfms, path):\n",
    "        self.path,self.fnames = path,fnames\n",
    "        self.open_fn = pil_loader\n",
    "        self.y=y\n",
    "        self.open_y_fn = pil_loader\n",
    "        assert(len(fnames)==len(y))\n",
    "        \n",
    "        self.n = self.get_n()\n",
    "        self.c = self.get_c()\n",
    "        self.tfms = tfms\n",
    "        \n",
    "    def get_x(self, i): return self.open_fn(os.path.join(self.path, self.fnames[i]))\n",
    "    def get_y(self, i): return self.open_y_fn(os.path.join(self.path, self.y[i]))\n",
    "    def get_n(self): return len(self.fnames)\n",
    "    def get_c(self): return 2\n",
    "    \n",
    "    def get(self, tfms, x, y):\n",
    "        for fn in tfms:\n",
    "            #pdb.set_trace()\n",
    "            x, y = fn(x, y)\n",
    "        return (x, y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x,y = self.get_x(idx),self.get_y(idx)\n",
    "        return self.get(self.tfms, x, y)\n",
    "    \n",
    "    def __len__(self): return self.n\n",
    "\n",
    "    def resize_imgs(self, targ, new_path):\n",
    "        dest = resize_imgs(self.fnames, targ, self.path, new_path)\n",
    "        return self.__class__(self.fnames, self.y, self.transform, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Seems to speed up training by ~2%\n",
    "class DataPrefetcher():\n",
    "    def __init__(self, loader, stop_after=None):\n",
    "        self.loader = loader\n",
    "        self.dataset = loader.dataset\n",
    "        self.stream = torch.cuda.Stream()\n",
    "        self.stop_after = stop_after\n",
    "        self.next_input = None\n",
    "        self.next_target = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.loader)\n",
    "    \n",
    "    def preload(self):\n",
    "        try:\n",
    "            self.next_input, self.next_target = next(self.loaditer)\n",
    "        except StopIteration:\n",
    "            self.next_input = None\n",
    "            self.next_target = None\n",
    "            return\n",
    "        with torch.cuda.stream(self.stream):\n",
    "            self.next_input = self.next_input.cuda(async=True)\n",
    "            self.next_target = self.next_target.cuda(async=True)\n",
    "\n",
    "    def __iter__(self):\n",
    "        count = 0\n",
    "        self.loaditer = iter(self.loader)\n",
    "        self.preload()\n",
    "        while self.next_input is not None:\n",
    "            torch.cuda.current_stream().wait_stream(self.stream)\n",
    "            input = self.next_input\n",
    "            target = self.next_target\n",
    "            self.preload()\n",
    "            count += 1\n",
    "            yield input, target\n",
    "            if type(self.stop_after) is int and (count > self.stop_after):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_bg_pil(x,y):\n",
    "    w, h = x.size\n",
    "    top = int(h/3.75)\n",
    "    bot = int(h*.9 + h/150)\n",
    "    pad_right=32-w%32\n",
    "    if pad_right == 32: pad_right = 0\n",
    "    return TTF.crop(x, top, 0, bot-top, w+pad_right), TTF.crop(y, top, 0, bot-top, w+pad_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RHF(object):\n",
    "    def __init__(self, p=0.5): self.p = p\n",
    "    def __call__(self, x, y):\n",
    "        if random.random() < self.p:\n",
    "            return TTF.hflip(x), TTF.hflip(y)\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RR(object):\n",
    "    def __init__(self, degrees=2): self.degrees = degrees\n",
    "    def __call__(self, x, y):\n",
    "        angle = random.uniform(-self.degrees, self.degrees)\n",
    "        return TTF.rotate(x, angle), TTF.rotate(y, angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfm_x_wrapper(tfm):\n",
    "    return lambda x,y: (tfm(x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RC():\n",
    "    def __init__(self, targ_sz):\n",
    "        self.targ_sz = targ_sz\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        rand_w = random.uniform(0, 1)\n",
    "        rand_h = random.uniform(0, 1)\n",
    "        w,h = x.size\n",
    "        t_w,t_h = self.targ_sz\n",
    "        start_x = np.floor(rand_w*(w-t_w)).astype(int)\n",
    "        start_y = np.floor(rand_h*(h-t_h)).astype(int)\n",
    "        return TTF.crop(x, start_y, start_x, t_h, t_w), TTF.crop(y, start_y, start_x, t_h, t_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y_ce(y_img):\n",
    "    y_new = np.zeros(y_img.shape, dtype=int)\n",
    "    y_new[y_img==VEHICLES] = 1\n",
    "    cutoff_y = int(y_new.shape[0]*.875)\n",
    "    y_new[cutoff_y:,:] = 0\n",
    "\n",
    "    y_new[y_img==ROADS] = 2\n",
    "    y_new[y_img==ROAD_LINES] = 2\n",
    "    return torch.from_numpy(y_new).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y(y_img):\n",
    "    yr = (y_img==ROADS) | (y_img==ROAD_LINES)\n",
    "    yc = (y_img==VEHICLES)\n",
    "    cutoff_y = int(yc.shape[0]*.875)\n",
    "    yc[cutoff_y:,:] = 0\n",
    "    rn = ~(yr | yc)\n",
    "    return torch.from_numpy(np.stack((rn,yc,yr)).astype(int))\n",
    "\n",
    "\n",
    "def xy_tensor(x,y):\n",
    "    y_img = np.array(y, np.int32, copy=False)\n",
    "    return TTF.to_tensor(x), convert_y_ce(y_img[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RRC(transforms.RandomResizedCrop):\n",
    "    def __call__(self, x, y):\n",
    "        i, j, h, w = self.get_params(x, self.scale, self.ratio)\n",
    "        x = TTF.resized_crop(x, i, j, h, w, self.size, self.interpolation)\n",
    "        y = TTF.resized_crop(y, i, j, h, w, self.size, self.interpolation)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_loader(f_ext, data_path, bs, size, workers=7, random_crop=False, pseudo_label=False, val_folder=None, val_bs=None):\n",
    "    # Data loading code\n",
    "    x_names = np.sort(np.array(glob(str(data_path/f'CameraRGB{f_ext}'/'*.png'))))\n",
    "    y_names = np.sort(np.array(glob(str(data_path/f'CameraSeg{f_ext}'/'*.png'))))\n",
    "\n",
    "    x_n = x_names.shape[0]\n",
    "    val_idxs = list(range(x_n-300, x_n))\n",
    "    \n",
    "    if pseudo_label:\n",
    "        x_names_test = np.sort(np.array(glob(f'../data/pseudo/CameraRGB{f_ext}/*.png')))\n",
    "        y_names_test = np.sort(np.array(glob(f'../data/pseudo/CameraSeg{f_ext}/*.png')))\n",
    "        x_names = np.concatenate((x_names, x_names_test))\n",
    "        x_names = np.concatenate((y_names, y_names_test))\n",
    "        print(f'Pseudo-Labels: {len(x_names_test)}')\n",
    "    if val_folder:\n",
    "        x_names_val = np.sort(np.array(glob(f'../data/{val_folder}/CameraRGB{f_ext}/*.png')))\n",
    "        y_names_val = np.sort(np.array(glob(f'../data/{val_folder}/CameraSeg{f_ext}/*.png')))\n",
    "        val_x,val_y = x_names_val, y_names_val\n",
    "        trn_x,trn_y = x_names, y_names\n",
    "        print(f'Val Labels:', len(val_x))\n",
    "    else:\n",
    "        ((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, x_names, y_names)\n",
    "    print(f'Val x:{len(val_x)}, y:{len(val_y)}')\n",
    "    print(f'Trn x:{len(trn_x)}, y:{len(trn_y)}')\n",
    "    print(f'All x:{len(x_names)}')\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    train_tfms = [\n",
    "        crop_bg_pil,\n",
    "        tfm_x_wrapper(transforms.ColorJitter(.2,.2,.2)),\n",
    "#         tfm_x_wrapper(Lighting(0.1, __imagenet_pca['eigval'], __imagenet_pca['eigvec'])),\n",
    "        RR(),\n",
    "        RHF(),\n",
    "#         RC((size,size)),\n",
    "        xy_tensor,\n",
    "        tfm_x_wrapper(normalize),\n",
    "    ]\n",
    "    if random_crop:\n",
    "        train_tfms.insert(3,RRC(size, scale=(0.4, 1.0)))\n",
    "    train_dataset = MatchedFilesDataset(trn_x, trn_y, train_tfms, path='')\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=bs, shuffle=True,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "\n",
    "    val_tfms = [\n",
    "        crop_bg_pil,\n",
    "        xy_tensor,\n",
    "        tfm_x_wrapper(normalize)\n",
    "    ]\n",
    "    val_dataset = MatchedFilesDataset(val_x, val_y, val_tfms, path='')\n",
    "    if val_bs is None: val_bs = bs\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=val_bs, shuffle=False,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "\n",
    "    train_loader = DataPrefetcher(train_loader)\n",
    "    val_loader = DataPrefetcher(val_loader)\n",
    "    \n",
    "    data = ModelData(data_path, train_loader, val_loader)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(x):\n",
    "    x_np = x.cpu().numpy()\n",
    "    x_np = np.rollaxis(x_np, 0, 3)\n",
    "    mean=np.array([0.485, 0.456, 0.406])\n",
    "    std=np.array([0.229, 0.224, 0.225])\n",
    "    x_np = x_np*std+mean\n",
    "    return x_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-net (ish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg11_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg11(pre): return children(vgg11_bn(pre))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_meta = {\n",
    "    resnet18:[8,6], resnet34:[8,6], resnet50:[8,6], resnet101:[8,6], resnet152:[8,6],\n",
    "    vgg11:[0,13], vgg16:[0,22], vgg19:[0,22],\n",
    "    resnext50:[8,6], resnext101:[8,6], resnext101_64:[8,6],\n",
    "    wrn:[8,6], inceptionresnet_2:[-2,9], inception_4:[-1,9],\n",
    "    dn121:[0,7], dn161:[0,7], dn169:[0,7], dn201:[0,7],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base(f):\n",
    "    cut,lr_cut = model_meta[f]\n",
    "    layers = cut_model(f(True), cut)\n",
    "    return nn.Sequential(*layers), lr_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = output\n",
    "    def remove(self): self.hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, up_in, x_in, n_out):\n",
    "        super().__init__()\n",
    "        up_out = x_out = n_out//2\n",
    "        self.x_conv  = nn.Conv2d(x_in,  x_out,  1)\n",
    "        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(n_out)\n",
    "        \n",
    "    def forward(self, up_p, x_p):\n",
    "        up_p = self.tr_conv(up_p)\n",
    "        x_p = self.x_conv(x_p)\n",
    "        cat_p = torch.cat([up_p,x_p], dim=1)\n",
    "        return self.bn(F.relu(cat_p, inplace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet34Mod(nn.Module):\n",
    "    def __init__(self, out=3, f=resnet34):\n",
    "        super().__init__()\n",
    "        m_base, lr_cut = get_base(f)\n",
    "        self.rn = m_base\n",
    "        self.lr_cut = lr_cut\n",
    "        self.sfs = [SaveFeatures(self.rn[i]) for i in [2,4,5,6]]\n",
    "        self.up1 = UnetBlock(512,256,256)\n",
    "        self.up2 = UnetBlock(256,128,256)\n",
    "        self.up3 = UnetBlock(256,64,128)\n",
    "        self.up4 = UnetBlock(128,64,64)\n",
    "        self.up5 = UnetBlock(64,32,32)\n",
    "        self.up6 = nn.ConvTranspose2d(32, out, 1)\n",
    "        self.x_skip = nn.Sequential(\n",
    "            nn.Conv2d(out,32,1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x_skip = self.x_skip(x)\n",
    "        x = self.rn(x)\n",
    "        x = self.up1(x, self.sfs[3].features)\n",
    "        x = self.up2(x, self.sfs[2].features)\n",
    "        x = self.up3(x, self.sfs[1].features)\n",
    "        x = self.up4(x, self.sfs[0].features)\n",
    "        x = self.up5(x, x_skip)\n",
    "        x = self.up6(x)\n",
    "        return torch.squeeze(x)\n",
    "    \n",
    "    def close(self):\n",
    "        for sf in self.sfs: sf.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet34(nn.Module):\n",
    "    def __init__(self, out=3, f=resnet34):\n",
    "        super().__init__()\n",
    "        m_base, lr_cut = get_base(f)\n",
    "        self.rn = m_base\n",
    "        self.lr_cut = lr_cut\n",
    "        self.sfs = [SaveFeatures(self.rn[i]) for i in [2,4,5,6]]\n",
    "        self.up1 = UnetBlock(512,256,256)\n",
    "        self.up2 = UnetBlock(256,128,256)\n",
    "        self.up3 = UnetBlock(256,64,256)\n",
    "        self.up4 = UnetBlock(256,64,256)\n",
    "        self.up5 = UnetBlock(256,out,16)\n",
    "        self.up6 = nn.ConvTranspose2d(16, out, 1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        inp = x\n",
    "        x = self.rn(x)\n",
    "        x = self.up1(x, self.sfs[3].features)\n",
    "        x = self.up2(x, self.sfs[2].features)\n",
    "        x = self.up3(x, self.sfs[1].features)\n",
    "        x = self.up4(x, self.sfs[0].features)\n",
    "        x = self.up5(x, inp)\n",
    "        x = self.up6(x)\n",
    "        return torch.squeeze(x)\n",
    "    \n",
    "    def close(self):\n",
    "        for sf in self.sfs: sf.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetModel():\n",
    "    def __init__(self,model,name='unet'):\n",
    "        self.model,self.name = model,name\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        if isinstance(self.model, FP16):\n",
    "            model = self.model.module\n",
    "        else:\n",
    "            model = self.model\n",
    "        lgs = list(split_by_idxs(children(model.rn), [model.lr_cut]))\n",
    "        return lgs + [children(model)[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carce_f_p_r(pred, targs):\n",
    "    _,idx = torch.max(pred, 1)\n",
    "    return fbeta_score(idx==1, targs[:,:,:]==1, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdce_f(pred, targs):\n",
    "    _,idx = torch.max(pred, 1)\n",
    "    f,p,r = fbeta_score(idx==2, targs[:,:,:]==2, beta=0.5)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carsig_f_p_r(pred, targs):\n",
    "    p2 = F.sigmoid(pred)\n",
    "    return fbeta_score(p2[:,0,:,:], targs[:,0,:,:], beta=2, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdsig_f(pred, targs):\n",
    "    p2 = F.sigmoid(pred)\n",
    "    f,p,r = fbeta_score(p2[:,1,:,:], targs[:,1,:,:], beta=0.5, threshold=0.5)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def car_f_p_r(pred, targs):\n",
    "    _,idx = torch.max(pred, 1)\n",
    "    return fbeta_score(idx==1, targs[:,1,:,:], beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rd_f(pred, targs):\n",
    "    _,idx = torch.max(pred, 1)\n",
    "    f,p,r = fbeta_score(idx==2, targs[:,2,:,:], beta=0.5)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_acc_sig(pred, targs):\n",
    "    p2 = F.sigmoid(pred)\n",
    "    return ((p2>0.5).long() == targs).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_acc_ce(preds, targs):\n",
    "    mx,idx = torch.max(preds, 1)\n",
    "    return (idx == targs).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_acc(pred, targs):\n",
    "    _,idx = torch.max(pred, 1)\n",
    "    _,t_idx = torch.max(targs,1)\n",
    "    return (idx == t_idx).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff_weight(pred, target, weight):\n",
    "    smooth = 1.\n",
    "    num,c,h,w = pred.shape\n",
    "    m1 = pred.view(num, c, -1)  # Flatten\n",
    "    m2 = target.view(num, c, -1)  # Flatten\n",
    "    intersection = (m1 * m2)\n",
    "    w = V(weight.view(1,-1,1))\n",
    "    i_w = (w*intersection).sum()\n",
    "    m1_w = (w*m1).sum()\n",
    "    m2_w = (w*m2).sum()\n",
    "    return (2. * i_w + smooth) / (m1_w + m2_w + smooth)\n",
    "\n",
    "def dice_coeff(pred, target):\n",
    "    smooth = 1.\n",
    "    num,c,h,w = pred.shape\n",
    "    m1 = pred.view(num, c, -1)  # Flatten\n",
    "    m2 = target.view(num, c, -1)  # Flatten\n",
    "    intersection = (m1 * m2).sum()\n",
    "    return (2. * intersection + smooth) / (m1.sum() + m2.sum() + smooth)\n",
    "\n",
    "\n",
    "class SoftDiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True, softmax=True):\n",
    "        super(SoftDiceLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.softmax = softmax\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = F.softmax(logits) if self.softmax else F.sigmoid(logits)\n",
    "        num = targets.size(0)  # Number of batches\n",
    "        targets = torch.cat(((targets==0).unsqueeze(1), (targets==1).unsqueeze(1), (targets==2).unsqueeze(1)), dim=1).float()\n",
    "        if isinstance(logits.data, torch.cuda.HalfTensor):\n",
    "            targets = targets.half()\n",
    "        else:\n",
    "            targets = targets.float()\n",
    "        if self.weight is not None:\n",
    "            score = dice_coeff_weight(probs, targets, self.weight)\n",
    "        else:\n",
    "            score = dice_coeff(probs, targets)\n",
    "        score = 1 - score.sum() / num\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbeta_score(y_pred, y_true, beta, threshold=None, eps=1e-9):\n",
    "    beta2 = beta**2\n",
    "\n",
    "    if threshold:\n",
    "        y_pred = torch.ge(y_pred.float(), threshold).float()\n",
    "    else:\n",
    "        y_pred = y_pred.float()\n",
    "    y_true = y_true.float()\n",
    "\n",
    "    true_positive = (y_pred * y_true).sum()\n",
    "    precision = true_positive/(y_pred.sum()+(eps))\n",
    "    recall = true_positive/(y_true.sum()+eps)\n",
    "    \n",
    "    fb = (precision*recall)/(precision*beta2 + recall + eps)*(1+beta2)\n",
    "    \n",
    "    return fb, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lyft_score(pred, target, weight):\n",
    "    num,c,h,w = pred.shape\n",
    "    pred = pred.view(num, c, -1)  # Flatten\n",
    "    target = target.view(num, c, -1)  # Flatten\n",
    "    intersection = (pred * target)\n",
    "    int_sum = intersection.sum(dim=-1)\n",
    "    pred_sum = pred.sum(dim=-1)\n",
    "    targ_sum = target.sum(dim=-1)\n",
    "    \n",
    "    eps = 1e-9\n",
    "    precision = int_sum / (pred_sum + eps)\n",
    "    recall = int_sum / (targ_sum + eps)\n",
    "    beta = V(weight ** 2)\n",
    "    \n",
    "    fnum = (1.+beta) * precision * recall\n",
    "    fden = beta * precision + recall + eps\n",
    "    \n",
    "    fscore = fnum / fden\n",
    "    \n",
    "#     fb = (precision*recall)/precision*beta + recall + eps\n",
    "    \n",
    "    avg_w = torch.cuda.FloatTensor([0,.5,.5])\n",
    "    favg = V(avg_w) * fscore\n",
    "#     pdb.set_trace()\n",
    "    return favg.sum(dim=-1)\n",
    "\n",
    "class FLoss(nn.Module):\n",
    "    def __init__(self, weight=torch.cuda.FloatTensor([1,2,0.5]), softmax=True):\n",
    "        super().__init__()\n",
    "        self.weight = weight\n",
    "        self.softmax = softmax\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = F.softmax(logits) if self.softmax else F.sigmoid(logits)\n",
    "        num = targets.size(0)  # Number of batches\n",
    "        targets = torch.cat(((targets==0).unsqueeze(1), (targets==1).unsqueeze(1), (targets==2).unsqueeze(1)), dim=1).float()\n",
    "        if isinstance(logits.data, torch.cuda.HalfTensor):\n",
    "            targets = targets.half()\n",
    "        else:\n",
    "            targets = targets.float()\n",
    "            \n",
    "        score = lyft_score(probs, targets, self.weight)\n",
    "        score = 1 - score.sum() / num\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learner(md, m_fn=Unet34, weights=[1,200,2], half=False, softmax=True, dice=False):\n",
    "    out_sz = 3 if softmax else 2\n",
    "    m = to_gpu(m_fn(out_sz))\n",
    "    models = UnetModel(m)\n",
    "    learn = ConvLearner(md, models)\n",
    "    learn.opt_fn=optim.Adam\n",
    "    class_weights = torch.cuda.FloatTensor(weights)\n",
    "    if half:\n",
    "        class_weights = class_weights.half()\n",
    "        learn.half()\n",
    "        \n",
    "#     if dice: learn.crit=SoftDiceLoss(weight=class_weights, softmax=softmax)\n",
    "#     else: learn.crit=nn.CrossEntropyLoss(weight=class_weights)\n",
    "    learn.crit = FLoss(softmax=softmax)\n",
    "    \n",
    "    if softmax: learn.metrics = [new_acc_ce, rdce_f, carce_f_p_r]\n",
    "    else: learn.metrics = [new_acc_sig, rdsig_f, carsig_f_p_r]\n",
    "    # learn.metrics=[new_acc, rd_f, car_f_p_r]\n",
    "    \n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = '-300'\n",
    "sz=192\n",
    "bs=64\n",
    "random_crop=True\n",
    "md = torch_loader(ext, PATH, bs, sz, workers, random_crop, pseudo_label, val_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(md, weights=[1,10,2], softmax=True)\n",
    "learn.load(f'600urn-19-weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-2\n",
    "wd=1e-7\n",
    "\n",
    "lrs = np.array([lr/200,lr/20,lr])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.set_bn_freeze(learn.model.rn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, wds=wd, cycle_len=30,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'300urn-{S_PREFIX}-rc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = '-300'\n",
    "sz=192\n",
    "bs=64\n",
    "random_crop=False\n",
    "md = torch_loader(ext, PATH, bs, sz, workers, random_crop, pseudo_label, val_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "wd=1e-7\n",
    "\n",
    "lrs = np.array([lr/50,lr/10,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(f'300urn-{S_PREFIX}-rc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.set_bn_freeze(learn.model.rn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs/5, 1, wds=wd, cycle_len=20,use_clr=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'300urn-{S_PREFIX}-nocrop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = ''\n",
    "sz=320\n",
    "bs=32\n",
    "random_crop=True\n",
    "md = torch_loader(ext, PATH, bs, sz, workers, random_crop, pseudo_label, val_folder, val_bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(md, m_fn=Unet34Mod, weights=[1,4,1], softmax=True, dice=False)\n",
    "learn.load(f'300urn-{S_PREFIX}-nocrop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "wd=1e-7\n",
    "\n",
    "lrs = np.array([lr/200,lr/20,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.set_bn_freeze(learn.model.rn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=6,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'600urn-{S_PREFIX}-320')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try old model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = ''\n",
    "sz=384\n",
    "bs=32\n",
    "random_crop=True\n",
    "md = torch_loader(ext, PATH, bs, sz, workers, random_crop, pseudo_label, val_folder, val_bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(md, m_fn=Unet34Mod, weights=[1,4,1], softmax=True, dice=False)\n",
    "# learn.load(f'600urn-{S_PREFIX}-320')\n",
    "learn.load(f'600urn-46_wide-384-nocrop-w8-pt3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "wd=1e-7\n",
    "\n",
    "lrs = np.array([lr/200,lr/20,lr])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.set_bn_freeze(learn.model.rn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=8,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'600urn-{S_PREFIX}-384')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nocrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = ''\n",
    "sz=384\n",
    "bs=16\n",
    "random_crop=False\n",
    "md = torch_loader(ext, PATH, bs, sz, workers, random_crop, pseudo_label, val_folder, val_bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(md, m_fn=Unet34Mod, weights=[1,4,2], softmax=True)\n",
    "# learn.load(f'600urn-{S_PREFIX}-384')\n",
    "learn.load(f'600urn-46_wide-384-nocrop-w8-pt3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "wd=1e-7\n",
    "\n",
    "lrs = np.array([lr/200,lr/20,lr])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "# learn.bn_freeze(True)\n",
    "learn.set_bn_freeze(learn.model.rn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=7,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'600urn-{S_PREFIX}-384-nocrop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(f'600urn-{S_PREFIX}-384-nocrop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs/40, 1, wds=wd, cycle_len=6,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'600urn-{S_PREFIX}-384-nocrop-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Labels: 400\n",
      "Val x:400, y:400\n",
      "Trn x:1000, y:1000\n",
      "All x:1000\n"
     ]
    }
   ],
   "source": [
    "ext = ''\n",
    "sz=384\n",
    "bs=16\n",
    "random_crop=False\n",
    "pseudo_label=False\n",
    "md = torch_loader(ext, Path(f'../data/test_sync'), bs, sz, workers, random_crop, pseudo_label, val_folder, val_bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(md, weights=[1,4,2], softmax=True)\n",
    "learn.load(f'../../all/models/600urn-19-weights')\n",
    "# learn.load(f'600urn-19-weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-4\n",
    "wd=1e-7\n",
    "\n",
    "lrs = np.array([lr/200,lr/20,lr])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "# learn.bn_freeze(True)\n",
    "learn.set_bn_freeze(learn.model.rn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f394243db59f4fc796f1418cd7e039bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   new_acc_ce rdce_f     carce_f_p_r \n",
      "    0      0.145589   0.140568   0.989221   0.992648   0.879309   0.77879    0.909724  \n",
      "    1      0.146041   0.140217   0.989179   0.992665   0.878673   0.776768   0.9096    \n",
      "    2      0.147214   0.138435   0.988865   0.992884   0.879978   0.761951   0.916789  \n",
      "    3      0.147191   0.135986   0.988644   0.993092   0.880492   0.74143    0.925724  \n",
      "    4      0.143483   0.134043   0.988989   0.993292   0.881569   0.74931    0.924034  \n",
      "    5      0.141316   0.131587   0.989126   0.99343    0.88248    0.755073   0.923048  \n",
      "    6      0.140458   0.129971   0.989436   0.993471   0.881575   0.768563   0.916804  \n",
      "    7      0.137621   0.128197   0.989189   0.993441   0.884149   0.753464   0.926153  \n",
      "    8      0.136814   0.127147   0.989139   0.993576   0.88489    0.749395   0.92884   \n",
      "    9      0.13755    0.127155   0.989183   0.993588   0.884994   0.749412   0.928939  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12715522050857545,\n",
       " 0.9891828393936157,\n",
       " 0.9935882425308228,\n",
       " 0.8849935531616211,\n",
       " 0.7494120323657989,\n",
       " 0.9289394092559814]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=10,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'../../all/models/600urn-{S_PREFIX}-384-test-sync')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "459dc6ebf8f24bb4b44891f0ac6d25fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   new_acc_ce rdce_f     carce_f_p_r \n",
      "    0      0.134497   0.126123   0.989258   0.993564   0.885389   0.751565   0.928666  \n",
      "    1      0.133935   0.125068   0.989338   0.993729   0.886101   0.7576     0.927235  \n",
      "    2      0.131956   0.122689   0.9896     0.993699   0.886667   0.768026   0.92401   \n",
      "    3      0.127743   0.12019    0.989379   0.993864   0.888559   0.755588   0.931495  \n",
      "    4      0.124045   0.116311   0.989709   0.994036   0.889538   0.772333   0.926364  \n",
      "    5      0.121281   0.112143   0.989514   0.99413    0.893563   0.759595   0.936756  \n",
      "    6      0.115918   0.109233   0.989654   0.994186   0.894487   0.770647   0.933615  \n",
      "    7      0.112806   0.106225   0.989764   0.994164   0.896186   0.772854   0.935147  \n",
      "    8      0.11171    0.10426    0.989864   0.994234   0.897799   0.774356   0.936681  \n",
      "    9      0.108841   0.103488   0.989813   0.9942     0.89829    0.776818   0.936318  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10348783969879151,\n",
       " 0.9898127055168152,\n",
       " 0.9941997098922729,\n",
       " 0.8982896041870118,\n",
       " 0.7768183517456054,\n",
       " 0.936317777633667]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs*2, 1, wds=wd, cycle_len=10,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'../../all/models/600urn-{S_PREFIX}-384-test-sync-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(f'../../all/models/600urn-{S_PREFIX}-384-test-sync-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "# learn.bn_freeze(True)\n",
    "learn.set_bn_freeze(learn.model.rn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50280c249e2a4f7ebc5834106826665e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   new_acc_ce rdce_f     carce_f_p_r \n",
      "    0      0.109571   0.103681   0.989738   0.994312   0.898351   0.774741   0.937158  \n",
      "    1      0.109245   0.10312    0.989967   0.994205   0.899333   0.779178   0.936713  \n",
      "    2      0.107333   0.101936   0.98974    0.994269   0.899105   0.779921   0.936093  \n",
      "    3      0.107632   0.100909   0.98986    0.994381   0.900073   0.779503   0.937624  \n",
      "    4      0.10554    0.098829   0.989888   0.994313   0.899509   0.785608   0.934864  \n",
      "    5      0.105629   0.097595   0.989898   0.994384   0.901546   0.782887   0.938289  \n",
      "    6      0.103488   0.096498   0.99004    0.994336   0.902227   0.793128   0.9353    \n",
      "    7      0.101206   0.09404    0.989796   0.994431   0.904113   0.77648    0.944302  \n",
      "    8      0.10019    0.092669   0.989892   0.994464   0.905269   0.778302   0.945178  \n",
      "    9      0.098402   0.092118   0.989953   0.994522   0.90461    0.790282   0.939601  \n",
      "    10     0.0948     0.089973   0.989953   0.994467   0.906543   0.781459   0.945745  \n",
      "    11     0.094413   0.08841    0.990125   0.994501   0.907411   0.78958    0.943714  \n",
      "    12     0.091473   0.086955   0.990032   0.994514   0.906864   0.790697   0.942666  \n",
      "    13     0.091723   0.086055   0.989945   0.994562   0.908501   0.781169   0.9487    \n",
      "    14     0.09015    0.084979   0.990186   0.994551   0.908991   0.79347    0.944493  \n",
      "    15     0.090186   0.08464    0.990165   0.994634   0.909184   0.796941   0.943468  \n",
      "    16     0.090007   0.083936   0.990098   0.994609   0.908766   0.798887   0.942236  \n",
      "    17     0.090096   0.083282   0.990037   0.994575   0.910887   0.784444   0.950439  \n",
      "    18     0.088996   0.082598   0.99014    0.994602   0.910957   0.790956   0.948134  \n",
      "    19     0.087084   0.082573   0.990106   0.994583   0.910714   0.792167   0.947428  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0825727128982544,\n",
       " 0.9901059222221374,\n",
       " 0.9945825791358948,\n",
       " 0.910714282989502,\n",
       " 0.7921670985221863,\n",
       " 0.9474284625053406]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs*2, 1, wds=wd, cycle_len=20,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'../../all/models/600urn-{S_PREFIX}-384-test-sync-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6d7535106a40ce8a14cef24007f0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   new_acc_ce rdce_f     carce_f_p_r \n",
      "    0      0.087486   0.082352   0.990123   0.994598   0.910943   0.791662   0.947877  \n",
      "    1      0.087626   0.082312   0.990226   0.994578   0.911404   0.79091    0.948734  \n",
      "    2      0.088524   0.082813   0.989965   0.994646   0.910315   0.790322   0.947494  \n",
      "    3      0.089228   0.08213    0.989996   0.994625   0.911703   0.786285   0.950877  \n",
      "    4      0.086607   0.082309   0.990047   0.994649   0.910638   0.793551   0.946672  \n",
      "    5      0.085851   0.081568   0.990181   0.994583   0.911556   0.792005   0.948655  \n",
      "    6      0.08585    0.082154   0.990063   0.994634   0.909012   0.803239   0.941038  \n",
      "    7      0.085637   0.081855   0.990155   0.994606   0.910608   0.796023   0.945783  \n",
      "    8      0.085109   0.0812     0.990103   0.994653   0.911597   0.789399   0.949629  \n",
      "    9      0.0851     0.081171   0.99039    0.994599   0.910546   0.80068    0.944113  \n",
      "    10     0.08518    0.081078   0.990097   0.994658   0.911544   0.79265    0.948285  \n",
      "    11     0.086131   0.080942   0.99016    0.994673   0.91101    0.798555   0.945477  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08094205379486084,\n",
       " 0.9901598238945007,\n",
       " 0.9946727705001831,\n",
       " 0.9110101079940796,\n",
       " 0.7985550284385681,\n",
       " 0.9454771137237549]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs/2, 1, wds=wd, cycle_len=12,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'../../all/models/600urn-{S_PREFIX}-384-test-sync-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a5f2dc57314a5785bc5d2ac9feaea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   new_acc_ce rdce_f     carce_f_p_r \n",
      "    0      0.086598   0.081035   0.990039   0.994675   0.912199   0.785793   0.951782  \n",
      "    1      0.084683   0.081003   0.990256   0.994644   0.911376   0.796076   0.946857  \n",
      "    2      0.084811   0.080734   0.99027    0.994609   0.911584   0.796699   0.946887  \n",
      "    3      0.083682   0.081136   0.990165   0.99463    0.910959   0.795896   0.946377  \n",
      "    4      0.084213   0.080848   0.990212   0.994618   0.911442   0.798561   0.945952  \n",
      "    5      0.085967   0.080883   0.990261   0.994618   0.911148   0.796144   0.94655   \n",
      "    6      0.085286   0.080845   0.990237   0.994619   0.911124   0.797462   0.945982  \n",
      "    7      0.084867   0.080766   0.990303   0.994623   0.911827   0.798674   0.94644   \n",
      "    8      0.085835   0.080714   0.990123   0.994626   0.911872   0.791557   0.949164  \n",
      "    9      0.085316   0.080738   0.990152   0.994639   0.911437   0.796116   0.94688   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08073795557022095,\n",
       " 0.9901516675949097,\n",
       " 0.9946390604972839,\n",
       " 0.9114365744590759,\n",
       " 0.7961157131195068,\n",
       " 0.9468801212310791]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs/20, 1, wds=wd, cycle_len=10,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'../../all/models/600urn-{S_PREFIX}-384-test-sync-5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on false answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = ''\n",
    "sz=384\n",
    "bs=16\n",
    "random_crop=False\n",
    "md = torch_loader(ext, Path(f'../data/test'), bs, sz, workers, random_crop, pseudo_label, val_folder, val_bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(md, m_fn=Unet34Mod, weights=[1,4,2], softmax=True)\n",
    "learn.load(f'../../all/models/600urn-{S_PREFIX}-384-test-sync-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-4\n",
    "wd=1e-7\n",
    "\n",
    "lrs = np.array([lr/200,lr/20,lr])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "# learn.bn_freeze(True)\n",
    "learn.set_bn_freeze(learn.model.rn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=10,use_clr_beta=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'../../all/models/600urn-{S_PREFIX}-384-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "86px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

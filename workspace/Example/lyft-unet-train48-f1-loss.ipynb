{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "# from fastai.dataset import *\n",
    "from fastai.models.resnet import vgg_resnet50\n",
    "\n",
    "import json\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('../data/all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(im, figsize=None, ax=None, alpha=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im, alpha=alpha)\n",
    "    ax.set_axis_off()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEHICLES=10\n",
    "ROADS=7\n",
    "ROAD_LINES=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DN = 'CameraRGB'\n",
    "MASKS_DN = 'CameraSeg'\n",
    "workers=7\n",
    "random_crop=True\n",
    "pseudo_label=False\n",
    "val_folder = 'sample_test_sync'\n",
    "# val_folder = 'val'\n",
    "S_PREFIX = '48_f1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets.folder import pil_loader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TTF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchedFilesDataset(Dataset):\n",
    "    def __init__(self, fnames, y, tfms, path):\n",
    "        self.path,self.fnames = path,fnames\n",
    "        self.open_fn = pil_loader\n",
    "        self.y=y\n",
    "        self.open_y_fn = pil_loader\n",
    "        assert(len(fnames)==len(y))\n",
    "        \n",
    "        self.n = self.get_n()\n",
    "        self.c = self.get_c()\n",
    "        self.tfms = tfms\n",
    "        \n",
    "    def get_x(self, i): return self.open_fn(os.path.join(self.path, self.fnames[i]))\n",
    "    def get_y(self, i): return self.open_y_fn(os.path.join(self.path, self.y[i]))\n",
    "    def get_n(self): return len(self.fnames)\n",
    "    def get_c(self): return 2\n",
    "    \n",
    "    def get(self, tfms, x, y):\n",
    "        for fn in tfms:\n",
    "            #pdb.set_trace()\n",
    "            x, y = fn(x, y)\n",
    "        return (x, y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x,y = self.get_x(idx),self.get_y(idx)\n",
    "        return self.get(self.tfms, x, y)\n",
    "    \n",
    "    def __len__(self): return self.n\n",
    "\n",
    "    def resize_imgs(self, targ, new_path):\n",
    "        dest = resize_imgs(self.fnames, targ, self.path, new_path)\n",
    "        return self.__class__(self.fnames, self.y, self.transform, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Seems to speed up training by ~2%\n",
    "class DataPrefetcher():\n",
    "    def __init__(self, loader, stop_after=None):\n",
    "        self.loader = loader\n",
    "        self.dataset = loader.dataset\n",
    "        self.stream = torch.cuda.Stream()\n",
    "        self.stop_after = stop_after\n",
    "        self.next_input = None\n",
    "        self.next_target = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.loader)\n",
    "    \n",
    "    def preload(self):\n",
    "        try:\n",
    "            self.next_input, self.next_target = next(self.loaditer)\n",
    "        except StopIteration:\n",
    "            self.next_input = None\n",
    "            self.next_target = None\n",
    "            return\n",
    "        with torch.cuda.stream(self.stream):\n",
    "            self.next_input = self.next_input.cuda(async=True)\n",
    "            self.next_target = self.next_target.cuda(async=True)\n",
    "\n",
    "    def __iter__(self):\n",
    "        count = 0\n",
    "        self.loaditer = iter(self.loader)\n",
    "        self.preload()\n",
    "        while self.next_input is not None:\n",
    "            torch.cuda.current_stream().wait_stream(self.stream)\n",
    "            input = self.next_input\n",
    "            target = self.next_target\n",
    "            self.preload()\n",
    "            count += 1\n",
    "            yield input, target\n",
    "            if type(self.stop_after) is int and (count > self.stop_after):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_bg_pil(x,y):\n",
    "    w, h = x.size\n",
    "    top = int(h/3.75)\n",
    "    bot = int(h*.9 + h/150)\n",
    "    pad_right=32-w%32\n",
    "    if pad_right == 32: pad_right = 0\n",
    "    return TTF.crop(x, top, 0, bot-top, w+pad_right), TTF.crop(y, top, 0, bot-top, w+pad_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RHF(object):\n",
    "    def __init__(self, p=0.5): self.p = p\n",
    "    def __call__(self, x, y):\n",
    "        if random.random() < self.p:\n",
    "            return TTF.hflip(x), TTF.hflip(y)\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RR(object):\n",
    "    def __init__(self, degrees=2): self.degrees = degrees\n",
    "    def __call__(self, x, y):\n",
    "        angle = random.uniform(-self.degrees, self.degrees)\n",
    "        return TTF.rotate(x, angle), TTF.rotate(y, angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfm_x_wrapper(tfm):\n",
    "    return lambda x,y: (tfm(x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RC():\n",
    "    def __init__(self, targ_sz):\n",
    "        self.targ_sz = targ_sz\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        rand_w = random.uniform(0, 1)\n",
    "        rand_h = random.uniform(0, 1)\n",
    "        w,h = x.size\n",
    "        t_w,t_h = self.targ_sz\n",
    "        start_x = np.floor(rand_w*(w-t_w)).astype(int)\n",
    "        start_y = np.floor(rand_h*(h-t_h)).astype(int)\n",
    "        return TTF.crop(x, start_y, start_x, t_h, t_w), TTF.crop(y, start_y, start_x, t_h, t_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y_ce(y_img):\n",
    "    y_new = np.zeros(y_img.shape, dtype=int)\n",
    "    y_new[y_img==VEHICLES] = 1\n",
    "    cutoff_y = int(y_new.shape[0]*.875)\n",
    "    y_new[cutoff_y:,:] = 0\n",
    "\n",
    "    y_new[y_img==ROADS] = 2\n",
    "    y_new[y_img==ROAD_LINES] = 2\n",
    "    return torch.from_numpy(y_new).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y(y_img):\n",
    "    yr = (y_img==ROADS) | (y_img==ROAD_LINES)\n",
    "    yc = (y_img==VEHICLES)\n",
    "    cutoff_y = int(yc.shape[0]*.875)\n",
    "    yc[cutoff_y:,:] = 0\n",
    "    rn = ~(yr | yc)\n",
    "    return torch.from_numpy(np.stack((rn,yc,yr)).astype(int))\n",
    "\n",
    "\n",
    "def xy_tensor(x,y):\n",
    "    y_img = np.array(y, np.int32, copy=False)\n",
    "    return TTF.to_tensor(x), convert_y_ce(y_img[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RRC(transforms.RandomResizedCrop):\n",
    "    def __call__(self, x, y):\n",
    "        i, j, h, w = self.get_params(x, self.scale, self.ratio)\n",
    "        x = TTF.resized_crop(x, i, j, h, w, self.size, self.interpolation)\n",
    "        y = TTF.resized_crop(y, i, j, h, w, self.size, self.interpolation)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_loader(f_ext, data_path, bs, size, workers=7, random_crop=False, pseudo_label=False, val_folder=None, val_bs=None):\n",
    "    # Data loading code\n",
    "    x_names = np.sort(np.array(glob(str(data_path/f'CameraRGB{f_ext}'/'*.png'))))\n",
    "    y_names = np.sort(np.array(glob(str(data_path/f'CameraSeg{f_ext}'/'*.png'))))\n",
    "\n",
    "    x_n = x_names.shape[0]\n",
    "    val_idxs = list(range(x_n-300, x_n))\n",
    "    \n",
    "    if pseudo_label:\n",
    "        x_names_test = np.sort(np.array(glob(f'../data/pseudo/CameraRGB{f_ext}/*.png')))\n",
    "        y_names_test = np.sort(np.array(glob(f'../data/pseudo/CameraSeg{f_ext}/*.png')))\n",
    "        x_names = np.concatenate((x_names, x_names_test))\n",
    "        x_names = np.concatenate((y_names, y_names_test))\n",
    "        print(f'Pseudo-Labels: {len(x_names_test)}')\n",
    "    if val_folder:\n",
    "        x_names_val = np.sort(np.array(glob(f'../data/{val_folder}/CameraRGB{f_ext}/*.png')))\n",
    "        y_names_val = np.sort(np.array(glob(f'../data/{val_folder}/CameraSeg{f_ext}/*.png')))\n",
    "        val_x,val_y = x_names_val, y_names_val\n",
    "        trn_x,trn_y = x_names, y_names\n",
    "        print(f'Val Labels:', len(val_x))\n",
    "    else:\n",
    "        ((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, x_names, y_names)\n",
    "    print(f'Val x:{len(val_x)}, y:{len(val_y)}')\n",
    "    print(f'Trn x:{len(trn_x)}, y:{len(trn_y)}')\n",
    "    print(f'All x:{len(x_names)}')\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    train_tfms = [\n",
    "        crop_bg_pil,\n",
    "        tfm_x_wrapper(transforms.ColorJitter(.2,.2,.2)),\n",
    "#         tfm_x_wrapper(Lighting(0.1, __imagenet_pca['eigval'], __imagenet_pca['eigvec'])),\n",
    "        RR(),\n",
    "        RHF(),\n",
    "#         RC((size,size)),\n",
    "        xy_tensor,\n",
    "        tfm_x_wrapper(normalize),\n",
    "    ]\n",
    "    if random_crop:\n",
    "        train_tfms.insert(3,RRC(size, scale=(0.4, 1.0)))\n",
    "    train_dataset = MatchedFilesDataset(trn_x, trn_y, train_tfms, path='')\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=bs, shuffle=True,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "\n",
    "    val_tfms = [\n",
    "        crop_bg_pil,\n",
    "        xy_tensor,\n",
    "        tfm_x_wrapper(normalize)\n",
    "    ]\n",
    "    val_dataset = MatchedFilesDataset(val_x, val_y, val_tfms, path='')\n",
    "    if val_bs is None: val_bs = bs\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=val_bs, shuffle=False,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "\n",
    "    train_loader = DataPrefetcher(train_loader)\n",
    "    val_loader = DataPrefetcher(val_loader)\n",
    "    \n",
    "    data = ModelData(data_path, train_loader, val_loader)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(x):\n",
    "    x_np = x.cpu().numpy()\n",
    "    x_np = np.rollaxis(x_np, 0, 3)\n",
    "    mean=np.array([0.485, 0.456, 0.406])\n",
    "    std=np.array([0.229, 0.224, 0.225])\n",
    "    x_np = x_np*std+mean\n",
    "    return x_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-net (ish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg11_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg11(pre): return children(vgg11_bn(pre))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_meta = {\n",
    "    resnet18:[8,6], resnet34:[8,6], resnet50:[8,6], resnet101:[8,6], resnet152:[8,6],\n",
    "    vgg11:[0,13], vgg16:[0,22], vgg19:[0,22],\n",
    "    resnext50:[8,6], resnext101:[8,6], resnext101_64:[8,6],\n",
    "    wrn:[8,6], inceptionresnet_2:[-2,9], inception_4:[-1,9],\n",
    "    dn121:[0,7], dn161:[0,7], dn169:[0,7], dn201:[0,7],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base(f):\n",
    "    cut,lr_cut = model_meta[f]\n",
    "    layers = cut_model(f(True), cut)\n",
    "    return nn.Sequential(*layers), lr_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = output\n",
    "    def remove(self): self.hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, up_in, x_in, n_out):\n",
    "        super().__init__()\n",
    "        up_out = x_out = n_out//2\n",
    "        self.x_conv  = nn.Conv2d(x_in,  x_out,  1)\n",
    "        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(n_out)\n",
    "        \n",
    "    def forward(self, up_p, x_p):\n",
    "        up_p = self.tr_conv(up_p)\n",
    "        x_p = self.x_conv(x_p)\n",
    "        cat_p = torch.cat([up_p,x_p], dim=1)\n",
    "        return self.bn(F.relu(cat_p, inplace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet34Mod(nn.Module):\n",
    "    def __init__(self, out=3, f=resnet34):\n",
    "        super().__init__()\n",
    "        m_base, lr_cut = get_base(f)\n",
    "        self.rn = m_base\n",
    "        self.lr_cut = lr_cut\n",
    "        self.sfs = [SaveFeatures(self.rn[i]) for i in [2,4,5,6]]\n",
    "        self.up1 = UnetBlock(512,256,256)\n",
    "        self.up2 = UnetBlock(256,128,256)\n",
    "        self.up3 = UnetBlock(256,64,128)\n",
    "        self.up4 = UnetBlock(128,64,64)\n",
    "        self.up5 = UnetBlock(64,32,32)\n",
    "        self.up6 = nn.ConvTranspose2d(32, out, 1)\n",
    "        self.x_skip = nn.Sequential(\n",
    "            nn.Conv2d(out,32,1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x_skip = self.x_skip(x)\n",
    "        x = self.rn(x)\n",
    "        x = self.up1(x, self.sfs[3].features)\n",
    "        x = self.up2(x, self.sfs[2].features)\n",
    "        x = self.up3(x, self.sfs[1].features)\n",
    "        x = self.up4(x, self.sfs[0].features)\n",
    "        x = self.up5(x, x_skip)\n",
    "        x = self.up6(x)\n",
    "        return torch.squeeze(x)\n",
    "    \n",
    "    def close(self):\n",
    "        for sf in self.sfs: sf.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetModel():\n",
    "    def __init__(self,model,name='unet'):\n",
    "        self.model,self.name = model,name\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        if isinstance(self.model, FP16):\n",
    "            model = self.model.module\n",
    "        else:\n",
    "            model = self.model\n",
    "        lgs = list(split_by_idxs(children(model.rn), [model.lr_cut]))\n",
    "        return lgs + [children(model)[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carce_f_p_r(pred, targs):\n",
    "    _,idx = torch.max(pred, 1)\n",
    "    return fbeta_score(idx==1, targs[:,:,:]==1, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdce_f(pred, targs):\n",
    "    _,idx = torch.max(pred, 1)\n",
    "    f,p,r = fbeta_score(idx==2, targs[:,:,:]==2, beta=0.5)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carsig_f_p_r(pred, targs):\n",
    "    p2 = F.sigmoid(pred)\n",
    "    return fbeta_score(p2[:,0,:,:], targs[:,0,:,:], beta=2, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdsig_f(pred, targs):\n",
    "    p2 = F.sigmoid(pred)\n",
    "    f,p,r = fbeta_score(p2[:,1,:,:], targs[:,1,:,:], beta=0.5, threshold=0.5)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def car_f_p_r(pred, targs):\n",
    "    _,idx = torch.max(pred, 1)\n",
    "    return fbeta_score(idx==1, targs[:,1,:,:], beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rd_f(pred, targs):\n",
    "    _,idx = torch.max(pred, 1)\n",
    "    f,p,r = fbeta_score(idx==2, targs[:,2,:,:], beta=0.5)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_acc_sig(pred, targs):\n",
    "    p2 = F.sigmoid(pred)\n",
    "    return ((p2>0.5).long() == targs).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_acc_ce(preds, targs):\n",
    "    mx,idx = torch.max(preds, 1)\n",
    "    return (idx == targs).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_acc(pred, targs):\n",
    "    _,idx = torch.max(pred, 1)\n",
    "    _,t_idx = torch.max(targs,1)\n",
    "    return (idx == t_idx).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff_weight(pred, target, weight):\n",
    "    smooth = 1.\n",
    "    num,c,h,w = pred.shape\n",
    "    m1 = pred.view(num, c, -1)  # Flatten\n",
    "    m2 = target.view(num, c, -1)  # Flatten\n",
    "    intersection = (m1 * m2)\n",
    "    w = V(weight.view(1,-1,1))\n",
    "    i_w = (w*intersection).sum()\n",
    "    m1_w = (w*m1).sum()\n",
    "    m2_w = (w*m2).sum()\n",
    "    return (2. * i_w + smooth) / (m1_w + m2_w + smooth)\n",
    "\n",
    "def dice_coeff(pred, target):\n",
    "    smooth = 1.\n",
    "    num,c,h,w = pred.shape\n",
    "    m1 = pred.view(num, c, -1)  # Flatten\n",
    "    m2 = target.view(num, c, -1)  # Flatten\n",
    "    intersection = (m1 * m2).sum()\n",
    "    return (2. * intersection + smooth) / (m1.sum() + m2.sum() + smooth)\n",
    "\n",
    "\n",
    "class SoftDiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True, softmax=True):\n",
    "        super(SoftDiceLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.softmax = softmax\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = F.softmax(logits) if self.softmax else F.sigmoid(logits)\n",
    "        num = targets.size(0)  # Number of batches\n",
    "        targets = torch.cat(((targets==0).unsqueeze(1), (targets==1).unsqueeze(1), (targets==2).unsqueeze(1)), dim=1).float()\n",
    "        if isinstance(logits.data, torch.cuda.HalfTensor):\n",
    "            targets = targets.half()\n",
    "        else:\n",
    "            targets = targets.float()\n",
    "        if self.weight is not None:\n",
    "            score = dice_coeff_weight(probs, targets, self.weight)\n",
    "        else:\n",
    "            score = dice_coeff(probs, targets)\n",
    "        score = 1 - score.sum() / num\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbeta_score(y_pred, y_true, beta, threshold=None, eps=1e-9):\n",
    "    beta2 = beta**2\n",
    "\n",
    "    if threshold:\n",
    "        y_pred = torch.ge(y_pred.float(), threshold).float()\n",
    "    else:\n",
    "        y_pred = y_pred.float()\n",
    "    y_true = y_true.float()\n",
    "\n",
    "    true_positive = (y_pred * y_true).sum()\n",
    "    precision = true_positive/(y_pred.sum()+(eps))\n",
    "    recall = true_positive/(y_true.sum()+eps)\n",
    "    \n",
    "    fb = (precision*recall)/(precision*beta2 + recall + eps)*(1+beta2)\n",
    "    \n",
    "    return fb, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lyft_score(pred, target, weight):\n",
    "    num,c,h,w = pred.shape\n",
    "    pred = pred.view(num, c, -1)  # Flatten\n",
    "    target = target.view(num, c, -1)  # Flatten\n",
    "    intersection = (pred * target)\n",
    "    int_sum = intersection.sum(dim=-1)\n",
    "    pred_sum = pred.sum(dim=-1)\n",
    "    targ_sum = target.sum(dim=-1)\n",
    "    \n",
    "    eps = 1e-9\n",
    "    precision = int_sum / (pred_sum + eps)\n",
    "    recall = int_sum / (targ_sum + eps)\n",
    "    beta = V(weight ** 2)\n",
    "    \n",
    "    fnum = (1.+beta) * precision * recall\n",
    "    fden = beta * precision + recall + eps\n",
    "    \n",
    "    fscore = fnum / fden\n",
    "    \n",
    "#     fb = (precision*recall)/precision*beta + recall + eps\n",
    "    \n",
    "    avg_w = torch.cuda.FloatTensor([0,.5,.5])\n",
    "    favg = V(avg_w) * fscore\n",
    "#     pdb.set_trace()\n",
    "    return favg.sum(dim=-1)\n",
    "\n",
    "class FLoss(nn.Module):\n",
    "    def __init__(self, weight=torch.cuda.FloatTensor([1,2,0.5]), softmax=True):\n",
    "        super().__init__()\n",
    "        self.weight = weight\n",
    "        self.softmax = softmax\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = F.softmax(logits) if self.softmax else F.sigmoid(logits)\n",
    "        num = targets.size(0)  # Number of batches\n",
    "        targets = torch.cat(((targets==0).unsqueeze(1), (targets==1).unsqueeze(1), (targets==2).unsqueeze(1)), dim=1).float()\n",
    "        if isinstance(logits.data, torch.cuda.HalfTensor):\n",
    "            targets = targets.half()\n",
    "        else:\n",
    "            targets = targets.float()\n",
    "            \n",
    "        score = lyft_score(probs, targets, self.weight)\n",
    "        score = 1 - score.sum() / num\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learner(md, m_fn=Unet34Mod, weights=[1,200,2], half=False, softmax=True, dice=False):\n",
    "    out_sz = 3 if softmax else 2\n",
    "    m = to_gpu(m_fn(out_sz))\n",
    "    models = UnetModel(m)\n",
    "    learn = ConvLearner(md, models)\n",
    "    learn.opt_fn=optim.Adam\n",
    "    class_weights = torch.cuda.FloatTensor(weights)\n",
    "    if half:\n",
    "        class_weights = class_weights.half()\n",
    "        learn.half()\n",
    "        \n",
    "#     if dice: learn.crit=SoftDiceLoss(weight=class_weights, softmax=softmax)\n",
    "#     else: learn.crit=nn.CrossEntropyLoss(weight=class_weights)\n",
    "    learn.crit = FLoss(softmax=softmax)\n",
    "    \n",
    "    if softmax: learn.metrics = [new_acc_ce, rdce_f, carce_f_p_r]\n",
    "    else: learn.metrics = [new_acc_sig, rdsig_f, carsig_f_p_r]\n",
    "    # learn.metrics=[new_acc, rd_f, car_f_p_r]\n",
    "    \n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Labels: 400\n",
      "Val x:400, y:400\n",
      "Trn x:10880, y:10880\n",
      "All x:10880\n"
     ]
    }
   ],
   "source": [
    "ext = '-300'\n",
    "sz=192\n",
    "bs=64\n",
    "random_crop=True\n",
    "md = torch_loader(ext, PATH, bs, sz, workers, random_crop, pseudo_label, val_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(md, m_fn=Unet34Mod, weights=[1,10,2], softmax=True)\n",
    "learn.load(f'600urn-46_wide-384-nocrop-w8-pt3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8e2dc78d0b44c593c0a3de37f7ec57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   new_acc_ce rdce_f     carce_f_p_r \n",
      "    0      0.247546   0.229154   0.950249   0.96414    0.768188   0.512816   0.878824  \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-2\n",
    "wd=1e-7\n",
    "\n",
    "lrs = np.array([lr/200,lr/20,lr])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.set_bn_freeze(learn.model.rn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5024cf82bedd439286a0971478660ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   new_acc_ce rdce_f     carce_f_p_r \n",
      "    0      0.202848   0.184353   0.964049   0.977637   0.823035   0.721886   0.855969  \n",
      "    1      0.206022   0.196577   0.979604   0.982654   0.722343   0.802145   0.70901   \n",
      "    2      0.202916   0.192921   0.974153   0.984009   0.724195   0.777986   0.715998  \n",
      "    3      0.203626   0.207406   0.966861   0.969568   0.748537   0.640312   0.788723  \n",
      "    4      0.200276   0.19691    0.966185   0.976675   0.78258    0.59785    0.851471  \n",
      "    5      0.199232   0.191862   0.977196   0.98676    0.788706   0.655887   0.836388  \n",
      "    6      0.198881   0.191629   0.974028   0.981234   0.72054    0.749055   0.717241  \n",
      "    7      0.201475   0.167222   0.973251   0.984657   0.813766   0.679756   0.859758  \n",
      "    8      0.194431   0.168796   0.973265   0.98436    0.826707   0.688581   0.872571  \n",
      "    9      0.196961   0.172389   0.977348   0.987117   0.826948   0.735611   0.855546  \n",
      "    10     0.192997   0.1856     0.975889   0.980194   0.786052   0.675495   0.823034  \n",
      "    11     0.196027   0.187484   0.978902   0.983176   0.804415   0.739117   0.824218  \n",
      "    12     0.195172   0.184758   0.964024   0.970828   0.799793   0.644758   0.855675  \n",
      "    13     0.205927   0.20339    0.964159   0.976951   0.767503   0.697137   0.789771  \n",
      "    14     0.196495   0.165428   0.968738   0.980409   0.826204   0.705243   0.865907  \n",
      "    15     0.191305   0.166775   0.974511   0.985036   0.810304   0.752535   0.82832   \n",
      "    16     0.19157    0.169364   0.977846   0.98649    0.821392   0.767905   0.837826  \n",
      "    17     0.193123   0.16019    0.979945   0.98782    0.820548   0.74444    0.845294  \n",
      "    18     0.187649   0.147075   0.977934   0.987379   0.865588   0.726764   0.909736  \n",
      "    19     0.187243   0.151484   0.979271   0.987975   0.857807   0.733581   0.896436  \n",
      "    20     0.183763   0.154481   0.981132   0.988123   0.866587   0.772179   0.895063  \n",
      "    21     0.180657   0.152909   0.984034   0.989295   0.867804   0.785849   0.892636  \n",
      "    22     0.180631   0.156448   0.982446   0.988933   0.849636   0.762701   0.875568  \n",
      "    23     0.180792   0.147703   0.982819   0.989716   0.865425   0.774468   0.894015  \n",
      "    24     0.177828   0.146013   0.982051   0.989465   0.869177   0.76443    0.900791  \n",
      "    25     0.17741    0.140986   0.983999   0.9903     0.876079   0.752351   0.914766  \n",
      "    26     0.174001   0.143441   0.982766   0.990194   0.880621   0.757498   0.91866   \n",
      "    27     0.173938   0.136557   0.983104   0.990119   0.882478   0.772625   0.915829  \n",
      "    28     0.17311    0.136113   0.984152   0.990469   0.88511    0.770804   0.920166  \n",
      "    29     0.169437   0.13778    0.984723   0.990879   0.889119   0.787564   0.919586  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13778027772903442,\n",
       " 0.984723334312439,\n",
       " 0.9908790469169617,\n",
       " 0.8891194176673889,\n",
       " 0.7875642895698547,\n",
       " 0.9195863890647888]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, 1, wds=wd, cycle_len=30,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'300urn-{S_PREFIX}-rc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Labels: 400\n",
      "Val x:400, y:400\n",
      "Trn x:10880, y:10880\n",
      "All x:10880\n"
     ]
    }
   ],
   "source": [
    "ext = '-300'\n",
    "sz=192\n",
    "bs=64\n",
    "random_crop=False\n",
    "md = torch_loader(ext, PATH, bs, sz, workers, random_crop, pseudo_label, val_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "wd=1e-7\n",
    "\n",
    "lrs = np.array([lr/50,lr/10,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(f'300urn-{S_PREFIX}-rc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.set_bn_freeze(learn.model.rn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7fe30a0ae89481590c02b785bcec4b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   new_acc_ce rdce_f     carce_f_p_r \n",
      "    0      0.170089   0.137212   0.984748   0.990769   0.889181   0.784033   0.920885  \n",
      "    1      0.168757   0.13638    0.984414   0.99081    0.889361   0.779024   0.922883  \n",
      "    2      0.171428   0.135954   0.984386   0.990777   0.889398   0.780579   0.922411  \n",
      "    3      0.170152   0.135539   0.984537   0.990856   0.889581   0.781235   0.922381  \n",
      "    4      0.168682   0.135313   0.984442   0.990843   0.889569   0.781528   0.922293  \n",
      "    5      0.169458   0.137019   0.984707   0.990935   0.88804    0.787262   0.918269  \n",
      "    6      0.166617   0.136537   0.984658   0.990849   0.887997   0.786334   0.91854   \n",
      "    7      0.165718   0.136408   0.984394   0.990855   0.888843   0.781022   0.921529  \n",
      "    8      0.172648   0.136132   0.984677   0.990892   0.888349   0.785872   0.919164  \n",
      "    9      0.165965   0.136011   0.984543   0.990974   0.888266   0.784479   0.919589  \n",
      "    10     0.167053   0.136309   0.984566   0.990948   0.88838    0.783826   0.919949  \n",
      "    11     0.168447   0.135752   0.984386   0.990961   0.888034   0.781641   0.920269  \n",
      "    12     0.170527   0.135479   0.984684   0.991059   0.889473   0.783679   0.921407  \n",
      "    13     0.172667   0.135255   0.984948   0.991065   0.888598   0.784415   0.920003  \n",
      "    14     0.165628   0.135583   0.984625   0.991067   0.888995   0.782412   0.921265  \n",
      "    15     0.169783   0.135552   0.984547   0.991061   0.889725   0.77482    0.924925  \n",
      "    16     0.171715   0.135165   0.984752   0.991059   0.889466   0.784539   0.921125  \n",
      "    17     0.17091    0.135317   0.984905   0.991071   0.888583   0.786845   0.919143  \n",
      "    18     0.169278   0.13587    0.984627   0.991037   0.889062   0.781084   0.92182   \n",
      "    19     0.169609   0.135088   0.984669   0.991119   0.890521   0.775948   0.92559   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13508803367614747,\n",
       " 0.9846685600280761,\n",
       " 0.9911191534996032,\n",
       " 0.8905205678939819,\n",
       " 0.7759480047225952,\n",
       " 0.9255895519256592]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs/5, 1, wds=wd, cycle_len=20,use_clr=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'300urn-{S_PREFIX}-nocrop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Labels: 400\n",
      "Val x:400, y:400\n",
      "Trn x:10880, y:10880\n",
      "All x:10880\n"
     ]
    }
   ],
   "source": [
    "ext = ''\n",
    "sz=320\n",
    "bs=32\n",
    "random_crop=True\n",
    "md = torch_loader(ext, PATH, bs, sz, workers, random_crop, pseudo_label, val_folder, val_bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(md, m_fn=Unet34Mod, weights=[1,4,1], softmax=True, dice=False)\n",
    "learn.load(f'300urn-{S_PREFIX}-nocrop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "wd=1e-7\n",
    "\n",
    "lrs = np.array([lr/200,lr/20,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.set_bn_freeze(learn.model.rn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3f4f51a1ba43489bd20365255d3d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   new_acc_ce rdce_f     carce_f_p_r \n",
      "    0      0.18873    0.197275   0.918527   0.917231   0.777588   0.688458   0.813364  \n",
      "    1      0.173717   0.179249   0.939995   0.940228   0.775247   0.735142   0.791756  \n",
      "    2      0.178055   0.165944   0.951087   0.956694   0.789012   0.748828   0.803877  \n",
      "    3      0.171826   0.15973    0.954186   0.962409   0.793787   0.73434    0.815654  \n",
      "    4      0.173311   0.158072   0.954551   0.962258   0.795108   0.736616   0.81619   \n",
      "    5      0.167668   0.154408   0.959693   0.968543   0.801751   0.739059   0.823458  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.154408016204834,\n",
       " 0.959692542552948,\n",
       " 0.9685426759719848,\n",
       " 0.8017510747909546,\n",
       " 0.7390592634677887,\n",
       " 0.8234576964378357]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=6,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'600urn-{S_PREFIX}-320')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try old model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Labels: 400\n",
      "Val x:400, y:400\n",
      "Trn x:10880, y:10880\n",
      "All x:10880\n"
     ]
    }
   ],
   "source": [
    "ext = ''\n",
    "sz=384\n",
    "bs=32\n",
    "random_crop=True\n",
    "md = torch_loader(ext, PATH, bs, sz, workers, random_crop, pseudo_label, val_folder, val_bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(md, m_fn=Unet34Mod, weights=[1,4,1], softmax=True, dice=False)\n",
    "# learn.load(f'600urn-{S_PREFIX}-320')\n",
    "learn.load(f'600urn-46_wide-384-nocrop-w8-pt3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "wd=1e-7\n",
    "\n",
    "lrs = np.array([lr/200,lr/20,lr])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.set_bn_freeze(learn.model.rn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=8,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'600urn-{S_PREFIX}-384')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nocrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Labels: 400\n",
      "Val x:400, y:400\n",
      "Trn x:10880, y:10880\n",
      "All x:10880\n"
     ]
    }
   ],
   "source": [
    "ext = ''\n",
    "sz=384\n",
    "bs=16\n",
    "random_crop=False\n",
    "md = torch_loader(ext, PATH, bs, sz, workers, random_crop, pseudo_label, val_folder, val_bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(md, m_fn=Unet34Mod, weights=[1,4,2], softmax=True)\n",
    "# learn.load(f'600urn-{S_PREFIX}-384')\n",
    "learn.load(f'600urn-46_wide-384-nocrop-w8-pt3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "wd=1e-7\n",
    "\n",
    "lrs = np.array([lr/200,lr/20,lr])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "# learn.bn_freeze(True)\n",
    "learn.set_bn_freeze(learn.model.rn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b064b4a65a43d791e51fa42d3d80c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   new_acc_ce rdce_f     carce_f_p_r \n",
      "    0      0.111197   0.122142   0.991557   0.995373   0.888856   0.810864   0.91155   \n",
      "    1      0.103146   0.117281   0.991262   0.995152   0.889752   0.809661   0.913252  \n",
      "    2      0.096495   0.11487    0.990991   0.995063   0.888172   0.811744   0.910715  \n",
      "    3      0.095678   0.115996   0.991002   0.995227   0.887116   0.82536    0.905045  \n",
      "    4      0.094184   0.11553    0.991051   0.995139   0.889841   0.819982   0.91032   \n",
      "    5      0.092221   0.11557    0.990944   0.995123   0.889019   0.822879   0.90845   \n",
      "    6      0.096215   0.114646   0.990965   0.995104   0.889259   0.822724   0.908774  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11464600801467896,\n",
       " 0.9909654664993286,\n",
       " 0.9951041412353515,\n",
       " 0.8892593288421631,\n",
       " 0.8227242517471314,\n",
       " 0.908773512840271]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=7,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'600urn-{S_PREFIX}-384-nocrop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(f'600urn-{S_PREFIX}-384-nocrop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs/40, 1, wds=wd, cycle_len=6,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'600urn-{S_PREFIX}-384-nocrop-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Labels: 400\n",
      "Val x:400, y:400\n",
      "Trn x:1000, y:1000\n",
      "All x:1000\n"
     ]
    }
   ],
   "source": [
    "ext = ''\n",
    "sz=384\n",
    "bs=16\n",
    "random_crop=False\n",
    "pseudo_label=False\n",
    "md = torch_loader(ext, Path(f'../data/test_sync'), bs, sz, workers, random_crop, pseudo_label, val_folder, val_bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(md, m_fn=Unet34Mod, weights=[1,4,2], softmax=True)\n",
    "learn.load(f'../../all/models/600urn-{S_PREFIX}-384-nocrop-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-4\n",
    "wd=1e-7\n",
    "\n",
    "lrs = np.array([lr/200,lr/20,lr])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "# learn.bn_freeze(True)\n",
    "learn.set_bn_freeze(learn.model.rn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbfd7f0ecdb41a5ad74bf4792c6c417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   new_acc_ce rdce_f     carce_f_p_r \n",
      "    0      0.11817    0.112662   0.989142   0.993774   0.892178   0.803204   0.919254  \n",
      "    1      0.116052   0.1102     0.988987   0.993742   0.892761   0.796598   0.922494  \n",
      "    2      0.113777   0.108062   0.989056   0.993809   0.893809   0.784796   0.928697  \n",
      "    3      0.108643   0.106193   0.989089   0.993905   0.89547    0.778805   0.933391  \n",
      "    4      0.108685   0.10472    0.988994   0.993874   0.896324   0.770809   0.938123  \n",
      "    5      0.106577   0.103612   0.98899    0.99392    0.89674    0.768136   0.939879  \n",
      "    6      0.10401    0.102283   0.989236   0.994061   0.897708   0.767337   0.941754  \n",
      "    7      0.105154   0.102104   0.989028   0.994003   0.897894   0.764729   0.943028  \n",
      "    8      0.103291   0.101639   0.989073   0.99405    0.897856   0.767837   0.941751  \n",
      "    9      0.103022   0.101463   0.98921    0.99409    0.89866    0.765648   0.943613  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10146326065063477,\n",
       " 0.9892098498344422,\n",
       " 0.9940895533561707,\n",
       " 0.8986597514152527,\n",
       " 0.7656480073928833,\n",
       " 0.9436133146286011]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=10,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'../../all/models/600urn-{S_PREFIX}-384-test-sync')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   new_acc_ce rdce_f     carce_f_p_r \n",
      "    0      0.10241    0.101067   0.989143   0.994094   0.898618   0.766381   0.943395  \n",
      "    1      0.101198   0.100089   0.989362   0.994121   0.899199   0.770358   0.942573  \n",
      "    2      0.099034   0.098954   0.98959    0.99421    0.900782   0.77345    0.943134  \n",
      "    3      0.099556   0.097827   0.989427   0.994252   0.900995   0.763879   0.947878  \n",
      "    4      0.095953   0.096156   0.989863   0.994318   0.902234   0.772998   0.94574   \n",
      "    5      0.094731   0.094762   0.989834   0.994406   0.904172   0.772237   0.94833   \n",
      "    6      0.096371   0.093765   0.989998   0.994469   0.905108   0.77258    0.949549  \n",
      "    7      0.094505   0.093257   0.990017   0.99447    0.905709   0.774709   0.94926   \n",
      "    8      0.093266   0.092638   0.99007    0.994505   0.906645   0.778839   0.948594  \n",
      "    9      0.093059   0.092378   0.990224   0.994527   0.906512   0.78155    0.947372  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09237840175628662,\n",
       " 0.9902240657806396,\n",
       " 0.9945272135734559,\n",
       " 0.906512451171875,\n",
       " 0.7815495955944062,\n",
       " 0.9473718452453613]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs*2, 1, wds=wd, cycle_len=10,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'../../all/models/600urn-{S_PREFIX}-384-test-sync-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(f'../../all/models/600urn-{S_PREFIX}-384-test-sync-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "# learn.bn_freeze(True)\n",
    "learn.set_bn_freeze(learn.model.rn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5dda7a4e344454e8eb133903e858a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   new_acc_ce rdce_f     carce_f_p_r \n",
      "    0      0.09199    0.092236   0.990093   0.994477   0.906793   0.778201   0.949132  \n",
      "    1      0.091661   0.09217    0.990069   0.994483   0.906956   0.77832    0.949233  \n",
      "    2      0.090707   0.091667   0.990258   0.994526   0.907073   0.78379    0.947215  \n",
      "    3      0.092482   0.091094   0.990234   0.994599   0.907612   0.778261   0.950195  \n",
      "    4      0.089815   0.090799   0.990414   0.994604   0.907949   0.78828    0.946388  \n",
      "    5      0.091522   0.089733   0.990204   0.994587   0.909115   0.779489   0.951546  \n",
      "    6      0.090334   0.089094   0.990239   0.994556   0.909393   0.78432    0.949972  \n",
      "    7      0.089484   0.08824    0.990361   0.994678   0.910773   0.788306   0.949869  \n",
      "    8      0.087035   0.087316   0.990437   0.99468    0.910903   0.786899   0.950793  \n",
      "    9      0.087122   0.086043   0.990532   0.994733   0.912434   0.789046   0.951787  \n",
      "    10     0.086413   0.08524    0.990517   0.994747   0.913228   0.789985   0.952517  \n",
      "    11     0.085285   0.084519   0.990491   0.994765   0.913517   0.785722   0.954539  \n",
      "    12     0.08643    0.08402    0.990572   0.994811   0.914389   0.789372   0.954157  \n",
      "    13     0.084936   0.083208   0.990642   0.994814   0.914727   0.790466   0.954396  \n",
      "    14     0.082856   0.082651   0.990799   0.994879   0.915012   0.79308    0.953756  \n",
      "    15     0.082693   0.08255    0.990733   0.994839   0.915179   0.794437   0.953408  \n",
      "    16     0.082211   0.082251   0.990753   0.9949     0.915579   0.797785   0.952483  \n",
      "    17     0.081601   0.08191    0.990777   0.994884   0.915621   0.79454    0.953932  \n",
      "    18     0.082047   0.082039   0.990618   0.994838   0.91565    0.792849   0.954546  \n",
      "    19     0.083198   0.081853   0.990802   0.994892   0.916196   0.795373   0.954266  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08185344934463501,\n",
       " 0.9908021664619446,\n",
       " 0.9948917269706726,\n",
       " 0.9161956715583801,\n",
       " 0.7953728652000427,\n",
       " 0.9542661547660828]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs*2, 1, wds=wd, cycle_len=20,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(f'../../all/models/600urn-{S_PREFIX}-384-test-sync-3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on false answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Labels: 400\n",
      "Val x:400, y:400\n",
      "Trn x:1000, y:1000\n",
      "All x:1000\n"
     ]
    }
   ],
   "source": [
    "ext = ''\n",
    "sz=384\n",
    "bs=16\n",
    "random_crop=False\n",
    "md = torch_loader(ext, Path(f'../data/test'), bs, sz, workers, random_crop, pseudo_label, val_folder, val_bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(md, m_fn=Unet34Mod, weights=[1,4,2], softmax=True)\n",
    "learn.load(f'../../all/models/600urn-{S_PREFIX}-384-test-sync-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-4\n",
    "wd=1e-7\n",
    "\n",
    "lrs = np.array([lr/200,lr/20,lr])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "# learn.bn_freeze(True)\n",
    "learn.set_bn_freeze(learn.model.rn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d21b86e40049bca5f62769b6ef0479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   new_acc_ce rdce_f     carce_f_p_r \n",
      "    0      0.133897   0.092389   0.990116   0.994565   0.906344   0.778303   0.948506  \n",
      "    1      0.135758   0.092133   0.989926   0.994577   0.906527   0.77062    0.951959  \n",
      "    2      0.135395   0.092283   0.989936   0.994589   0.90572    0.766414   0.952775  \n",
      "    3      0.133047   0.092023   0.989813   0.99458    0.905949   0.766848   0.952692  \n",
      "    4      0.135392   0.092168   0.989403   0.994602   0.905293   0.753645   0.957539  \n",
      "    5      0.134308   0.091608   0.989512   0.994631   0.905908   0.754302   0.957883  \n",
      "    6      0.134722   0.091383   0.989489   0.994631   0.905993   0.754047   0.9579    \n",
      "    7      0.130334   0.091068   0.989501   0.994664   0.905969   0.752944   0.958482  \n",
      "    8      0.132506   0.09124    0.989403   0.994619   0.90597    0.752518   0.958647  \n",
      "    9      0.131529   0.091114   0.989463   0.994631   0.906054   0.754274   0.957985  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09111426591873169,\n",
       " 0.9894629120826721,\n",
       " 0.9946308827400208,\n",
       " 0.9060536670684814,\n",
       " 0.7542741203308105,\n",
       " 0.9579853081703186]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=10,use_clr_beta=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'../../all/models/600urn-{S_PREFIX}-384-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "86px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

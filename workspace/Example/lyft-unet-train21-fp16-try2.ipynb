{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "# from fastai.dataset import *\n",
    "from fastai.models.resnet import vgg_resnet50\n",
    "\n",
    "import json\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('../data/all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(im, figsize=None, ax=None, alpha=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im, alpha=alpha)\n",
    "    ax.set_axis_off()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEHICLES=10\n",
    "ROADS=7\n",
    "ROAD_LINES=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_PREFIX = '21-fp16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets.folder import pil_loader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TTF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchedFilesDataset(Dataset):\n",
    "    def __init__(self, fnames, y, tfms, path):\n",
    "        self.path,self.fnames = path,fnames\n",
    "        self.open_fn = pil_loader\n",
    "        self.y=y\n",
    "        self.open_y_fn = pil_loader\n",
    "        assert(len(fnames)==len(y))\n",
    "        \n",
    "        self.n = self.get_n()\n",
    "        self.c = self.get_c()\n",
    "        self.tfms = tfms\n",
    "#         self.sz = self.get_sz()\n",
    "        \n",
    "#     def get_sz(self): return self.transform.sz\n",
    "    def get_x(self, i): return self.open_fn(os.path.join(self.path, self.fnames[i]))\n",
    "    def get_y(self, i): return self.open_y_fn(os.path.join(self.path, self.y[i]))\n",
    "    def get_n(self): return len(self.fnames)\n",
    "    def get_c(self): return 2\n",
    "    \n",
    "    def get(self, tfms, x, y):\n",
    "        for fn in tfms:\n",
    "            #pdb.set_trace()\n",
    "            x, y = fn(x, y)\n",
    "        return (x, y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x,y = self.get_x(idx),self.get_y(idx)\n",
    "        return self.get(self.tfms, x, y)\n",
    "    \n",
    "    def __len__(self): return self.n\n",
    "\n",
    "    def resize_imgs(self, targ, new_path):\n",
    "        dest = resize_imgs(self.fnames, targ, self.path, new_path)\n",
    "        return self.__class__(self.fnames, self.y, self.transform, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Seems to speed up training by ~2%\n",
    "class DataPrefetcher():\n",
    "    def __init__(self, loader, stop_after=None):\n",
    "        self.loader = loader\n",
    "        self.dataset = loader.dataset\n",
    "        self.stream = torch.cuda.Stream()\n",
    "        self.stop_after = stop_after\n",
    "        self.next_input = None\n",
    "        self.next_target = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.loader)\n",
    "    \n",
    "    def preload(self):\n",
    "        try:\n",
    "            self.next_input, self.next_target = next(self.loaditer)\n",
    "        except StopIteration:\n",
    "            self.next_input = None\n",
    "            self.next_target = None\n",
    "            return\n",
    "        with torch.cuda.stream(self.stream):\n",
    "            self.next_input = self.next_input.cuda(async=True)\n",
    "            self.next_target = self.next_target.cuda(async=True)\n",
    "\n",
    "    def __iter__(self):\n",
    "        count = 0\n",
    "        self.loaditer = iter(self.loader)\n",
    "        self.preload()\n",
    "        while self.next_input is not None:\n",
    "            torch.cuda.current_stream().wait_stream(self.stream)\n",
    "            input = self.next_input\n",
    "            target = self.next_target\n",
    "            self.preload()\n",
    "            count += 1\n",
    "            yield input, target\n",
    "            if type(self.stop_after) is int and (count > self.stop_after):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_bg_pil(x,y):\n",
    "    w, h = x.size\n",
    "    top = int(h/3.75)\n",
    "    bot = int(h*.9 + h/150)\n",
    "    pad_right=32-w%32\n",
    "    return TTF.crop(x, top, 0, bot-top, w+pad_right), TTF.crop(y, top, 0, bot-top, w+pad_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RHF(object):\n",
    "    def __init__(self, p=0.5): self.p = p\n",
    "    def __call__(self, x, y):\n",
    "        if random.random() < self.p:\n",
    "            return TTF.hflip(x), TTF.hflip(y)\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RR(object):\n",
    "    def __init__(self, degrees=2): self.degrees = degrees\n",
    "    def __call__(self, x, y):\n",
    "        angle = random.uniform(-self.degrees, self.degrees)\n",
    "        return TTF.rotate(x, angle), TTF.rotate(y, angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfm_x_wrapper(tfm):\n",
    "    return lambda x,y: (tfm(x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RC():\n",
    "    def __init__(self, targ_sz):\n",
    "        self.targ_sz = targ_sz\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        rand_w = random.uniform(0, 1)\n",
    "        rand_h = random.uniform(0, 1)\n",
    "        w,h = x.size\n",
    "        t_w,t_h = self.targ_sz\n",
    "        start_x = np.floor(rand_w*(w-t_w)).astype(int)\n",
    "        start_y = np.floor(rand_h*(h-t_h)).astype(int)\n",
    "        return TTF.crop(x, start_y, start_x, t_h, t_w), TTF.crop(y, start_y, start_x, t_h, t_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_names_val = np.array(glob(str(PATH/'AnswersRGB'/'*.png')))\n",
    "y_names_val = np.array(glob(str(PATH/'AnswersSeg'/'*.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y(y_img):\n",
    "    y_new = np.zeros(y_img.shape, dtype=int)\n",
    "    y_new[y_img==VEHICLES] = 1\n",
    "    cutoff_y = int(y_new.shape[0]*.83)\n",
    "    y_new[cutoff_y:,:] = 0\n",
    "\n",
    "    y_new[y_img==ROADS] = 2\n",
    "    y_new[y_img==ROAD_LINES] = 2\n",
    "    return torch.from_numpy(y_new).long()\n",
    "\n",
    "def xy_tensor(x,y):\n",
    "    y_img = np.array(y, np.int32, copy=False)\n",
    "    return TTF.to_tensor(x), convert_y(y_img[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_loader(f_ext, data_path, bs, size, workers=7, random_crop=False):\n",
    "    # Data loading code\n",
    "    x_names = np.sort(np.array(glob(str(data_path/f'CameraRGB{f_ext}'/'*.png'))))\n",
    "    y_names = np.sort(np.array(glob(str(data_path/f'CameraSeg{f_ext}'/'*.png'))))\n",
    "#     x_names_val = np.array(glob(str(data_path/f'AnswersRGB{f_ext}'/'*.png')))\n",
    "#     y_names_val = np.array(glob(str(data_path/f'AnswersSeg{f_ext}'/'*.png')))\n",
    "    val_idxs = list(range(100))\n",
    "#     val_x,val_y = x_names_val, y_names_val\n",
    "#     trn_x,trn_y = x_names, y_names\n",
    "    ((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, x_names, y_names)\n",
    "    normalize = transforms.Normalize(mean=[0.4914 , 0.48216, 0.44653], std=[0.24703, 0.24349, 0.26159])\n",
    "    \n",
    "    train_tfms = [\n",
    "        crop_bg_pil,\n",
    "        tfm_x_wrapper(transforms.ColorJitter(.2,.2,.2)),\n",
    "#         tfm_x_wrapper(Lighting(0.1, __imagenet_pca['eigval'], __imagenet_pca['eigvec'])),\n",
    "        RR(),\n",
    "        RHF(),\n",
    "#         RC((size,size)),\n",
    "        xy_tensor,\n",
    "        tfm_x_wrapper(normalize),\n",
    "    ]\n",
    "    if random_crop:\n",
    "        train_tfms.insert(3,RC((size,size)))\n",
    "    train_dataset = MatchedFilesDataset(trn_x, trn_y, train_tfms, path='')\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=bs, shuffle=True,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "\n",
    "    val_tfms = [\n",
    "        crop_bg_pil,\n",
    "        xy_tensor,\n",
    "        tfm_x_wrapper(normalize)\n",
    "    ]\n",
    "    val_dataset = MatchedFilesDataset(val_x, val_y, val_tfms, path='')\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=bs, shuffle=False,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "\n",
    "    train_loader = DataPrefetcher(train_loader)\n",
    "    val_loader = DataPrefetcher(val_loader)\n",
    "    \n",
    "    data = ModelData(data_path, train_loader, val_loader)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(x):\n",
    "    x_np = x.cpu().numpy()\n",
    "    x_np = np.rollaxis(x_np, 0, 3)\n",
    "    mean=np.array([0.4914 , 0.48216, 0.44653])\n",
    "    std=np.array([0.24703, 0.24349, 0.26159])\n",
    "    x_np = x_np*std+mean\n",
    "    return x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 96\n",
    "bs = 2\n",
    "data = torch_loader('-150', PATH, bs, sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = data.trn_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out = denorm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_acc(preds, targs):\n",
    "    mx,idx = torch.max(preds, 1)\n",
    "    return (idx == targs).float().mean()\n",
    "def dice_mult(pred, targs):\n",
    "#     pred = (pred>0).float()\n",
    "    mx,idx = torch.max(pred, 1)\n",
    "    pred = idx.float()\n",
    "    targs = targs.float()\n",
    "    return 2. * (pred*targs).sum() / (pred+targs).sum()\n",
    "def dice(pred, targs):\n",
    "    pred = (pred>0).float()\n",
    "    return 2. * (pred*targs).sum() / (pred+targs).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-net (ish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg11_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg11(pre): return children(vgg11_bn(pre))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_meta = {\n",
    "    resnet18:[8,6], resnet34:[8,6], resnet50:[8,6], resnet101:[8,6], resnet152:[8,6],\n",
    "    vgg11:[0,13], vgg16:[0,22], vgg19:[0,22],\n",
    "    resnext50:[8,6], resnext101:[8,6], resnext101_64:[8,6],\n",
    "    wrn:[8,6], inceptionresnet_2:[-2,9], inception_4:[-1,9],\n",
    "    dn121:[0,7], dn161:[0,7], dn169:[0,7], dn201:[0,7],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base(f):\n",
    "    cut,lr_cut = model_meta[f]\n",
    "    layers = cut_model(f(False), cut)\n",
    "    return nn.Sequential(*layers), lr_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = output\n",
    "    def remove(self): self.hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, up_in, x_in, n_out):\n",
    "        super().__init__()\n",
    "        up_out = x_out = n_out//2\n",
    "        self.x_conv  = nn.Conv2d(x_in,  x_out,  1)\n",
    "        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(n_out)\n",
    "        \n",
    "    def forward(self, up_p, x_p):\n",
    "        up_p = self.tr_conv(up_p)\n",
    "        x_p = self.x_conv(x_p)\n",
    "        cat_p = torch.cat([up_p,x_p], dim=1)\n",
    "        return self.bn(F.relu(cat_p, inplace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet34(nn.Module):\n",
    "    def __init__(self, f=resnet34):\n",
    "        super().__init__()\n",
    "        m_base, lr_cut = get_base(f)\n",
    "        self.rn = m_base\n",
    "        self.lr_cut = lr_cut\n",
    "        self.sfs = [SaveFeatures(self.rn[i]) for i in [2,4,5,6]]\n",
    "        self.up1 = UnetBlock(512,256,256)\n",
    "        self.up2 = UnetBlock(256,128,256)\n",
    "        self.up3 = UnetBlock(256,64,256)\n",
    "        self.up4 = UnetBlock(256,64,256)\n",
    "        self.up5 = UnetBlock(256,3,16)\n",
    "        self.up6 = nn.ConvTranspose2d(16, 3, 1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        inp = x\n",
    "        x = F.relu(self.rn(x), inplace=True)\n",
    "        x = self.up1(x, self.sfs[3].features)\n",
    "        x = self.up2(x, self.sfs[2].features)\n",
    "        x = self.up3(x, self.sfs[1].features)\n",
    "        x = self.up4(x, self.sfs[0].features)\n",
    "        x = self.up5(x, inp)\n",
    "        x = self.up6(x)\n",
    "        return torch.squeeze(x)\n",
    "    \n",
    "    def close(self):\n",
    "        for sf in self.sfs: sf.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet16(nn.Module):\n",
    "    def __init__(self, f=vgg11_bn):\n",
    "        super().__init__()\n",
    "        m_base, lr_cut = get_base(f)\n",
    "        self.rn = m_base\n",
    "        self.lr_cut = lr_cut\n",
    "        self.sfs = [SaveFeatures(self.rn[0][i]) for i in [5,12,22,32,42]]\n",
    "        self.up0 = UnetBlock(512,512,256)\n",
    "        self.up1 = UnetBlock(256,512,256)\n",
    "        self.up2 = UnetBlock(256,256,256)\n",
    "        self.up3 = UnetBlock(256,128,256)\n",
    "        self.up4 = UnetBlock(256,64,256)\n",
    "        self.up5  = nn.Conv2d(256,3,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.rn(x))\n",
    "        x = self.up0(x, self.sfs[4].features)\n",
    "        x = self.up1(x, self.sfs[3].features)\n",
    "        x = self.up2(x, self.sfs[2].features)\n",
    "        x = self.up3(x, self.sfs[1].features)\n",
    "        x = self.up4(x, self.sfs[0].features)\n",
    "        x = self.up5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet11(nn.Module):\n",
    "    def __init__(self, f=vgg11):\n",
    "        super().__init__()\n",
    "        m_base, lr_cut = get_base(f)\n",
    "        self.rn = m_base\n",
    "        self.lr_cut = lr_cut\n",
    "        self.sfs = [SaveFeatures(self.rn[0][i]) for i in [2,6,13,20,27]]\n",
    "        self.up0 = UnetBlock(512,512,256)\n",
    "        self.up1 = UnetBlock(256,512,256)\n",
    "        self.up2 = UnetBlock(256,256,256)\n",
    "        self.up3 = UnetBlock(256,128,256)\n",
    "        self.up4 = UnetBlock(256,64,256)\n",
    "        self.up5  = nn.Conv2d(256,3,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.rn(x))\n",
    "        x = self.up0(x, self.sfs[4].features)\n",
    "        x = self.up1(x, self.sfs[3].features)\n",
    "        x = self.up2(x, self.sfs[2].features)\n",
    "        x = self.up3(x, self.sfs[1].features)\n",
    "        x = self.up4(x, self.sfs[0].features)\n",
    "        x = self.up5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetModel():\n",
    "    def __init__(self,model,name='unet'):\n",
    "        self.model,self.name = model,name\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        if isinstance(self.model, FP16):\n",
    "            model = self.model.module\n",
    "        else:\n",
    "            model = self.model\n",
    "        lgs = list(split_by_idxs(children(model.rn), [model.lr_cut]))\n",
    "#         print('LGS:', lgs)\n",
    "#         print('Add:', children(model)[1:])\n",
    "        return lgs + [children(model)[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learner(md, m_fn=Unet34):\n",
    "#     m = to_gpu(Unet34())\n",
    "    m = to_gpu(m_fn())\n",
    "    models = UnetModel(m)\n",
    "    learn = ConvLearner(md, models)\n",
    "#     learn.opt_fn=optim.Adam\n",
    "    learn.opt_fn = optim.SGD\n",
    "    \n",
    "#     class_weights = torch.FloatTensor([1,10,2]).cuda()\n",
    "#     learn.crit=nn.CrossEntropyLoss(weight=class_weights)\n",
    "    \n",
    "    learn.crit=nn.CrossEntropyLoss()\n",
    "#     learn.crit=FocalLoss(2)\n",
    "#     learn.crit = nn.BCEWithLogitsLoss()\n",
    "    learn.metrics=[new_acc]\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = '-150'\n",
    "sz = 96\n",
    "bs = 256\n",
    "md = torch_loader('-150', PATH, bs, sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model params: 140\n",
      "Group params: 48\n",
      "32 shape: torch.Size([64, 3, 7, 7])\n",
      "group shape: torch.Size([64, 3, 7, 7])\n",
      "32 shape: torch.Size([64])\n",
      "group shape: torch.Size([64])\n",
      "32 shape: torch.Size([64])\n",
      "group shape: torch.Size([64])\n",
      "32 shape: torch.Size([64, 64, 3, 3])\n",
      "group shape: torch.Size([64, 64, 3, 3])\n",
      "32 shape: torch.Size([64])\n",
      "group shape: torch.Size([64])\n",
      "32 shape: torch.Size([64])\n",
      "group shape: torch.Size([64])\n",
      "32 shape: torch.Size([64, 64, 3, 3])\n",
      "group shape: torch.Size([64, 64, 3, 3])\n",
      "32 shape: torch.Size([64])\n",
      "group shape: torch.Size([64])\n",
      "32 shape: torch.Size([64])\n",
      "group shape: torch.Size([64])\n",
      "32 shape: torch.Size([64, 64, 3, 3])\n",
      "group shape: torch.Size([64, 64, 3, 3])\n",
      "32 shape: torch.Size([64])\n",
      "group shape: torch.Size([64])\n",
      "32 shape: torch.Size([64])\n",
      "group shape: torch.Size([64])\n",
      "32 shape: torch.Size([64, 64, 3, 3])\n",
      "group shape: torch.Size([64, 64, 3, 3])\n",
      "32 shape: torch.Size([64])\n",
      "group shape: torch.Size([64])\n",
      "32 shape: torch.Size([64])\n",
      "group shape: torch.Size([64])\n",
      "32 shape: torch.Size([64, 64, 3, 3])\n",
      "group shape: torch.Size([64, 64, 3, 3])\n",
      "32 shape: torch.Size([64])\n",
      "group shape: torch.Size([64])\n",
      "32 shape: torch.Size([64])\n",
      "group shape: torch.Size([64])\n",
      "32 shape: torch.Size([64, 64, 3, 3])\n",
      "group shape: torch.Size([64, 64, 3, 3])\n",
      "32 shape: torch.Size([64])\n",
      "group shape: torch.Size([64])\n",
      "32 shape: torch.Size([64])\n",
      "group shape: torch.Size([64])\n",
      "32 shape: torch.Size([128, 64, 3, 3])\n",
      "group shape: torch.Size([128, 64, 3, 3])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "32 shape: torch.Size([128, 128, 3, 3])\n",
      "group shape: torch.Size([128, 128, 3, 3])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "32 shape: torch.Size([128, 64, 1, 1])\n",
      "group shape: torch.Size([128, 64, 1, 1])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "32 shape: torch.Size([128, 128, 3, 3])\n",
      "group shape: torch.Size([128, 128, 3, 3])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "32 shape: torch.Size([128, 128, 3, 3])\n",
      "group shape: torch.Size([128, 128, 3, 3])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "32 shape: torch.Size([128, 128, 3, 3])\n",
      "group shape: torch.Size([128, 128, 3, 3])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "32 shape: torch.Size([128, 128, 3, 3])\n",
      "group shape: torch.Size([128, 128, 3, 3])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "32 shape: torch.Size([128, 128, 3, 3])\n",
      "group shape: torch.Size([128, 128, 3, 3])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "32 shape: torch.Size([128, 128, 3, 3])\n",
      "group shape: torch.Size([128, 128, 3, 3])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "Group params: 60\n",
      "32 shape: torch.Size([256, 128, 3, 3])\n",
      "group shape: torch.Size([256, 128, 3, 3])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256, 256, 3, 3])\n",
      "group shape: torch.Size([256, 256, 3, 3])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256, 128, 1, 1])\n",
      "group shape: torch.Size([256, 128, 1, 1])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256, 256, 3, 3])\n",
      "group shape: torch.Size([256, 256, 3, 3])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256, 256, 3, 3])\n",
      "group shape: torch.Size([256, 256, 3, 3])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256, 256, 3, 3])\n",
      "group shape: torch.Size([256, 256, 3, 3])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256, 256, 3, 3])\n",
      "group shape: torch.Size([256, 256, 3, 3])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256, 256, 3, 3])\n",
      "group shape: torch.Size([256, 256, 3, 3])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256, 256, 3, 3])\n",
      "group shape: torch.Size([256, 256, 3, 3])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256, 256, 3, 3])\n",
      "group shape: torch.Size([256, 256, 3, 3])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256, 256, 3, 3])\n",
      "group shape: torch.Size([256, 256, 3, 3])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256, 256, 3, 3])\n",
      "group shape: torch.Size([256, 256, 3, 3])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256, 256, 3, 3])\n",
      "group shape: torch.Size([256, 256, 3, 3])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([512, 256, 3, 3])\n",
      "group shape: torch.Size([512, 256, 3, 3])\n",
      "32 shape: torch.Size([512])\n",
      "group shape: torch.Size([512])\n",
      "32 shape: torch.Size([512])\n",
      "group shape: torch.Size([512])\n",
      "32 shape: torch.Size([512, 512, 3, 3])\n",
      "group shape: torch.Size([512, 512, 3, 3])\n",
      "32 shape: torch.Size([512])\n",
      "group shape: torch.Size([512])\n",
      "32 shape: torch.Size([512])\n",
      "group shape: torch.Size([512])\n",
      "32 shape: torch.Size([512, 256, 1, 1])\n",
      "group shape: torch.Size([512, 256, 1, 1])\n",
      "32 shape: torch.Size([512])\n",
      "group shape: torch.Size([512])\n",
      "32 shape: torch.Size([512])\n",
      "group shape: torch.Size([512])\n",
      "32 shape: torch.Size([512, 512, 3, 3])\n",
      "group shape: torch.Size([512, 512, 3, 3])\n",
      "32 shape: torch.Size([512])\n",
      "group shape: torch.Size([512])\n",
      "32 shape: torch.Size([512])\n",
      "group shape: torch.Size([512])\n",
      "32 shape: torch.Size([512, 512, 3, 3])\n",
      "group shape: torch.Size([512, 512, 3, 3])\n",
      "32 shape: torch.Size([512])\n",
      "group shape: torch.Size([512])\n",
      "32 shape: torch.Size([512])\n",
      "group shape: torch.Size([512])\n",
      "32 shape: torch.Size([512, 512, 3, 3])\n",
      "group shape: torch.Size([512, 512, 3, 3])\n",
      "32 shape: torch.Size([512])\n",
      "group shape: torch.Size([512])\n",
      "32 shape: torch.Size([512])\n",
      "group shape: torch.Size([512])\n",
      "32 shape: torch.Size([512, 512, 3, 3])\n",
      "group shape: torch.Size([512, 512, 3, 3])\n",
      "32 shape: torch.Size([512])\n",
      "group shape: torch.Size([512])\n",
      "32 shape: torch.Size([512])\n",
      "group shape: torch.Size([512])\n",
      "Group params: 32\n",
      "32 shape: torch.Size([128, 256, 1, 1])\n",
      "group shape: torch.Size([128, 256, 1, 1])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "32 shape: torch.Size([512, 128, 2, 2])\n",
      "group shape: torch.Size([512, 128, 2, 2])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([128, 128, 1, 1])\n",
      "group shape: torch.Size([128, 128, 1, 1])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "32 shape: torch.Size([256, 128, 2, 2])\n",
      "group shape: torch.Size([256, 128, 2, 2])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([128, 64, 1, 1])\n",
      "group shape: torch.Size([128, 64, 1, 1])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "32 shape: torch.Size([256, 128, 2, 2])\n",
      "group shape: torch.Size([256, 128, 2, 2])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([128, 64, 1, 1])\n",
      "group shape: torch.Size([128, 64, 1, 1])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "32 shape: torch.Size([256, 128, 2, 2])\n",
      "group shape: torch.Size([256, 128, 2, 2])\n",
      "32 shape: torch.Size([128])\n",
      "group shape: torch.Size([128])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([256])\n",
      "group shape: torch.Size([256])\n",
      "32 shape: torch.Size([8, 3, 1, 1])\n",
      "group shape: torch.Size([8, 3, 1, 1])\n",
      "32 shape: torch.Size([8])\n",
      "group shape: torch.Size([8])\n",
      "32 shape: torch.Size([256, 8, 2, 2])\n",
      "group shape: torch.Size([256, 8, 2, 2])\n",
      "32 shape: torch.Size([8])\n",
      "group shape: torch.Size([8])\n",
      "32 shape: torch.Size([16])\n",
      "group shape: torch.Size([16])\n",
      "32 shape: torch.Size([16])\n",
      "group shape: torch.Size([16])\n",
      "32 shape: torch.Size([16, 3, 1, 1])\n",
      "group shape: torch.Size([16, 3, 1, 1])\n",
      "32 shape: torch.Size([3])\n",
      "group shape: torch.Size([3])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b89e966f28d4e4196904aba00a55333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   new_acc                 \n",
      "    0      nan        nan        0.604671  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([nan]), 0.6046707630157471]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(.00001,1,wds=1e-5,cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(md.trn_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(md.val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading from train6 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('600urn-18-resnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr=1e-1\n",
    "lr=1e-1\n",
    "# lr=4e-3\n",
    "wd=1e-5\n",
    "\n",
    "lrs = np.array([lr/200,lr/20,lr])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(.00001,1,wds=wd,cycle_len=15,use_clr=(5,8), loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'128urn-{S_PREFIX}-tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(f'128urn-{S_PREFIX}-tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.bn_freeze(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr=1e-1\n",
    "lr=1e-2\n",
    "# lr=4e-3\n",
    "wd=1e-6\n",
    "\n",
    "lrs = np.array([lr/200,lr/20,lr])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit(lrs/2, 1, wds=wd, cycle_len=10,use_clr=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit(lrs/2, 1, wds=wd, cycle_len=10,use_clr=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'128urn-{S_PREFIX}-0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(f'128urn-{S_PREFIX}-0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(md.val_dl))\n",
    "py = to_np(learn.model(V(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py = np.argmax(py,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(denorm(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(py[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(y[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 256x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = '-300'\n",
    "sz=192\n",
    "bs=64\n",
    "md = torch_loader(ext, PATH, bs, sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-1\n",
    "wd=1e-6\n",
    "\n",
    "lrs = np.array([lr/200,lr/20,lr])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.load(f'128urn-{S_PREFIX}-0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr,1,wds=wd, cycle_len=10,use_clr=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'256urn-{S_PREFIX}-tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.bn_freeze(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(f'256urn-{S_PREFIX}-tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs/4,1,wds=wd, cycle_len=8,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs/4,1,wds=wd, cycle_len=8,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'256urn-{S_PREFIX}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(f'256urn-{S_PREFIX}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(md.trn_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(md.val_dl))\n",
    "py = to_np(learn.model(V(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py = np.argmax(py,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(denorm(x[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(py[-1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(y[-1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 512x512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DN = 'CameraRGB'\n",
    "MASKS_DN = 'CameraSeg'\n",
    "sz=288\n",
    "bs=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = ''\n",
    "sz=288\n",
    "bs=24\n",
    "md = torch_loader(ext, PATH, bs, sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(f'256urn-{S_PREFIX}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=4e-2\n",
    "wd=5e-7\n",
    "\n",
    "lrs = np.array([lr/200,lr/20,lr])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit(lr,1, wds=wd, cycle_len=4,use_clr=(5,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr,1, wds=wd, cycle_len=4,use_clr=(5,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'600urn-{S_PREFIX}-tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(f'600urn-{S_PREFIX}-tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.bn_freeze(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = np.array([lr/200,lr/30,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs/10,1, wds=wd,cycle_len=4,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs/10,1, wds=wd,cycle_len=4,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'600urn-{S_PREFIX}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs/8,1, wds=wd,cycle_len=4,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs/8,1, wds=wd,cycle_len=4,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'600urn-{S_PREFIX}-last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs/8,1, wds=wd,cycle_len=20,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs/50,1, wds=wd,cycle_len=5,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs/200,1, wds=wd,cycle_len=3,use_clr=(2,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'600urn-{S_PREFIX}-e20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(f'600urn-{S_PREFIX}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = ''\n",
    "sz=288\n",
    "bs=16\n",
    "md = torch_loader(ext, PATH, bs, sz, random_crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.load(f'600urn-{S_PREFIX}-full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.bn_freeze(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs/10,1, wds=wd,cycle_len=4,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs/10,1, wds=wd,cycle_len=4,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs/10,1, wds=wd,cycle_len=4,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'600urn-{S_PREFIX}-full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(md.val_dl))\n",
    "py = to_np(learn.model(V(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py = np.argmax(py,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(denorm(x[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(py[10]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(y[10]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, skvideo.io, json, base64\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO, StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_base = get_base()\n",
    "m = to_gpu(Unet34(m_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_summary(m, [3,608,800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.load('1024urn')\n",
    "load_model(m, str(PATH/f'models/600urn-{S_PREFIX}.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = sys.argv[-1]\n",
    "file = 'test_video.mp4'\n",
    "\n",
    "if file == 'demo.py':\n",
    "    print(\"Error loading video\")\n",
    "    quit\n",
    "\n",
    "# Define encoder function\n",
    "def encode(array):\n",
    "    pil_img = Image.fromarray(array)\n",
    "    buff = BytesIO()\n",
    "    pil_img.save(buff, format=\"PNG\")\n",
    "    return base64.b64encode(buff.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "video = skvideo.io.vread(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resized_video = np.array([scipy.misc.imresize(f, size=(512,512)) for f in video])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    if np.mean(x) > 1:\n",
    "        x = x/255\n",
    "    m,s = imagenet_stats\n",
    "    x = (x-m)/s\n",
    "    return x\n",
    "def preprocess(video):\n",
    "    f1_norm = normalize(video)\n",
    "    f1_roll = np.rollaxis(f1_norm, 3, 1)\n",
    "    f1_pad = np.pad(f1_roll, [(0,0),(0,0),(0,8),(0,0)], mode='constant')\n",
    "    return f1_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = preprocess(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(0,f1.shape[0],8):\n",
    "    xv = VV(torch.from_numpy(f1[i:i+8]).contiguous().float())\n",
    "    preds = m(xv)\n",
    "    mx,idx = torch.max(preds, 1)\n",
    "    idx_slice = idx[:,:-8,:]\n",
    "    results.append(idx_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_stacked = torch.cat(results,0)\n",
    "r_np = r_stacked.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_res(index):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 15))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(video[index])\n",
    "    ax2.imshow(r_np[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_key = {}\n",
    "\n",
    "# Frame numbering starts at 1\n",
    "frame_idx = 1\n",
    "for frame in r_np:\n",
    "    # Look for red cars :)\n",
    "    binary_car_result = (frame==1).astype('uint8')\n",
    "#     print(np.mean(binary_car_result))\n",
    "    \n",
    "    # Look for road :)\n",
    "    binary_road_result = (frame==2).astype('uint8')\n",
    "\n",
    "    answer_key[frame_idx] = [encode(binary_car_result), encode(binary_road_result)]\n",
    "    \n",
    "    # Increment frame\n",
    "    frame_idx+=1\n",
    "\n",
    "# Print output in proper json format\n",
    "tester_data = json.dumps(answer_key)\n",
    "with open('tester_data_multi_take2', 'w') as f:\n",
    "    f.write(tester_data)\n",
    "print(json.dumps(answer_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import misc\n",
    "def decode(packet):\n",
    "\timg = base64.b64decode(packet)\n",
    "\tfilename = PATH/'image.png'\n",
    "\twith open(filename, 'wb') as f:\n",
    "\t\t\tf.write(img)\n",
    "\tresult = misc.imread(filename)\n",
    "\treturn result\n",
    "\n",
    "with open('results.json') as json_data:\n",
    "\tans_data = json.loads(json_data.read())\n",
    "\tjson_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ans(index):\n",
    "    ans = decode(ans_data[str(index)][0])\n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 15))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(r_np[index])\n",
    "    ax1.set_title('Mine', fontsize=35)\n",
    "    ax2.imshow(ans)\n",
    "    ax2.set_title('Answer', fontsize=35)\n",
    "    ax3.imshow(video[index])\n",
    "    ax2.set_title('Original', fontsize=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ans(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = decode(ans_data['1'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_res(index):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 15))\n",
    "    f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "86px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "# from fastai.dataset import *\n",
    "from fastai.models.resnet import vgg_resnet50\n",
    "\n",
    "import json\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('../data/all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(im, figsize=None, ax=None, alpha=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im, alpha=alpha)\n",
    "    ax.set_axis_off()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEHICLES=10\n",
    "ROADS=7\n",
    "ROAD_LINES=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DN = 'CameraRGB'\n",
    "MASKS_DN = 'CameraSeg'\n",
    "workers=7\n",
    "random_crop=True\n",
    "pseudo_label=False\n",
    "val_folder = 'sample_test_sync'\n",
    "# val_folder = 'val'\n",
    "S_PREFIX = '47_vgg11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets.folder import pil_loader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TTF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchedFilesDataset(Dataset):\n",
    "    def __init__(self, fnames, y, tfms, path):\n",
    "        self.path,self.fnames = path,fnames\n",
    "        self.open_fn = pil_loader\n",
    "        self.y=y\n",
    "        self.open_y_fn = pil_loader\n",
    "        assert(len(fnames)==len(y))\n",
    "        \n",
    "        self.n = self.get_n()\n",
    "        self.c = self.get_c()\n",
    "        self.tfms = tfms\n",
    "        \n",
    "    def get_x(self, i): return self.open_fn(os.path.join(self.path, self.fnames[i]))\n",
    "    def get_y(self, i): return self.open_y_fn(os.path.join(self.path, self.y[i]))\n",
    "    def get_n(self): return len(self.fnames)\n",
    "    def get_c(self): return 2\n",
    "    \n",
    "    def get(self, tfms, x, y):\n",
    "        for fn in tfms:\n",
    "            #pdb.set_trace()\n",
    "            x, y = fn(x, y)\n",
    "        return (x, y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x,y = self.get_x(idx),self.get_y(idx)\n",
    "        return self.get(self.tfms, x, y)\n",
    "    \n",
    "    def __len__(self): return self.n\n",
    "\n",
    "    def resize_imgs(self, targ, new_path):\n",
    "        dest = resize_imgs(self.fnames, targ, self.path, new_path)\n",
    "        return self.__class__(self.fnames, self.y, self.transform, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Seems to speed up training by ~2%\n",
    "class DataPrefetcher():\n",
    "    def __init__(self, loader, stop_after=None):\n",
    "        self.loader = loader\n",
    "        self.dataset = loader.dataset\n",
    "        self.stream = torch.cuda.Stream()\n",
    "        self.stop_after = stop_after\n",
    "        self.next_input = None\n",
    "        self.next_target = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.loader)\n",
    "    \n",
    "    def preload(self):\n",
    "        try:\n",
    "            self.next_input, self.next_target = next(self.loaditer)\n",
    "        except StopIteration:\n",
    "            self.next_input = None\n",
    "            self.next_target = None\n",
    "            return\n",
    "        with torch.cuda.stream(self.stream):\n",
    "            self.next_input = self.next_input.cuda(async=True)\n",
    "            self.next_target = self.next_target.cuda(async=True)\n",
    "\n",
    "    def __iter__(self):\n",
    "        count = 0\n",
    "        self.loaditer = iter(self.loader)\n",
    "        self.preload()\n",
    "        while self.next_input is not None:\n",
    "            torch.cuda.current_stream().wait_stream(self.stream)\n",
    "            input = self.next_input\n",
    "            target = self.next_target\n",
    "            self.preload()\n",
    "            count += 1\n",
    "            yield input, target\n",
    "            if type(self.stop_after) is int and (count > self.stop_after):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_bg_pil(x,y):\n",
    "    w, h = x.size\n",
    "    top = int(h/3.75)\n",
    "    bot = int(h*.9 + h/150)\n",
    "    pad_right=32-w%32\n",
    "    if pad_right == 32: pad_right = 0\n",
    "    return TTF.crop(x, top, 0, bot-top, w+pad_right), TTF.crop(y, top, 0, bot-top, w+pad_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RHF(object):\n",
    "    def __init__(self, p=0.5): self.p = p\n",
    "    def __call__(self, x, y):\n",
    "        if random.random() < self.p:\n",
    "            return TTF.hflip(x), TTF.hflip(y)\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RR(object):\n",
    "    def __init__(self, degrees=2): self.degrees = degrees\n",
    "    def __call__(self, x, y):\n",
    "        angle = random.uniform(-self.degrees, self.degrees)\n",
    "        return TTF.rotate(x, angle), TTF.rotate(y, angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfm_x_wrapper(tfm):\n",
    "    return lambda x,y: (tfm(x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RC():\n",
    "    def __init__(self, targ_sz):\n",
    "        self.targ_sz = targ_sz\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        rand_w = random.uniform(0, 1)\n",
    "        rand_h = random.uniform(0, 1)\n",
    "        w,h = x.size\n",
    "        t_w,t_h = self.targ_sz\n",
    "        start_x = np.floor(rand_w*(w-t_w)).astype(int)\n",
    "        start_y = np.floor(rand_h*(h-t_h)).astype(int)\n",
    "        return TTF.crop(x, start_y, start_x, t_h, t_w), TTF.crop(y, start_y, start_x, t_h, t_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y_ce(y_img):\n",
    "    y_new = np.zeros(y_img.shape, dtype=int)\n",
    "    y_new[y_img==VEHICLES] = 1\n",
    "    cutoff_y = int(y_new.shape[0]*.875)\n",
    "    y_new[cutoff_y:,:] = 0\n",
    "\n",
    "    y_new[y_img==ROADS] = 2\n",
    "    y_new[y_img==ROAD_LINES] = 2\n",
    "    return torch.from_numpy(y_new).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y(y_img):\n",
    "    yr = (y_img==ROADS) | (y_img==ROAD_LINES)\n",
    "    yc = (y_img==VEHICLES)\n",
    "    cutoff_y = int(yc.shape[0]*.875)\n",
    "    yc[cutoff_y:,:] = 0\n",
    "    rn = ~(yr | yc)\n",
    "    return torch.from_numpy(np.stack((rn,yc,yr)).astype(int))\n",
    "\n",
    "\n",
    "def xy_tensor(x,y):\n",
    "    y_img = np.array(y, np.int32, copy=False)\n",
    "    return TTF.to_tensor(x), convert_y_ce(y_img[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RRC(transforms.RandomResizedCrop):\n",
    "    def __call__(self, x, y):\n",
    "        i, j, h, w = self.get_params(x, self.scale, self.ratio)\n",
    "        x = TTF.resized_crop(x, i, j, h, w, self.size, self.interpolation)\n",
    "        y = TTF.resized_crop(y, i, j, h, w, self.size, self.interpolation)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_loader(f_ext, data_path, bs, size, workers=7, random_crop=False, pseudo_label=False, val_folder=None, val_bs=None):\n",
    "    # Data loading code\n",
    "    x_names = np.sort(np.array(glob(str(data_path/f'CameraRGB{f_ext}'/'*.png'))))\n",
    "    y_names = np.sort(np.array(glob(str(data_path/f'CameraSeg{f_ext}'/'*.png'))))\n",
    "\n",
    "    x_n = x_names.shape[0]\n",
    "    val_idxs = list(range(x_n-300, x_n))\n",
    "    \n",
    "    if pseudo_label:\n",
    "        x_names_test = np.sort(np.array(glob(f'../data/pseudo/CameraRGB{f_ext}/*.png')))\n",
    "        y_names_test = np.sort(np.array(glob(f'../data/pseudo/CameraSeg{f_ext}/*.png')))\n",
    "        x_names = np.concatenate((x_names, x_names_test))\n",
    "        x_names = np.concatenate((y_names, y_names_test))\n",
    "        print(f'Pseudo-Labels: {len(x_names_test)}')\n",
    "    if val_folder:\n",
    "        x_names_val = np.sort(np.array(glob(f'../data/{val_folder}/CameraRGB{f_ext}/*.png')))\n",
    "        y_names_val = np.sort(np.array(glob(f'../data/{val_folder}/CameraSeg{f_ext}/*.png')))\n",
    "        val_x,val_y = x_names_val, y_names_val\n",
    "        trn_x,trn_y = x_names, y_names\n",
    "        print(f'Val Labels:', len(val_x))\n",
    "    else:\n",
    "        ((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, x_names, y_names)\n",
    "    print(f'Val x:{len(val_x)}, y:{len(val_y)}')\n",
    "    print(f'Trn x:{len(trn_x)}, y:{len(trn_y)}')\n",
    "    print(f'All x:{len(x_names)}')\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    train_tfms = [\n",
    "        crop_bg_pil,\n",
    "        tfm_x_wrapper(transforms.ColorJitter(.2,.2,.2)),\n",
    "#         tfm_x_wrapper(Lighting(0.1, __imagenet_pca['eigval'], __imagenet_pca['eigvec'])),\n",
    "        RR(),\n",
    "        RHF(),\n",
    "#         RC((size,size)),\n",
    "        xy_tensor,\n",
    "        tfm_x_wrapper(normalize),\n",
    "    ]\n",
    "    if random_crop:\n",
    "        train_tfms.insert(3,RRC(size, scale=(0.4, 1.0)))\n",
    "    train_dataset = MatchedFilesDataset(trn_x, trn_y, train_tfms, path='')\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=bs, shuffle=True,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "\n",
    "    val_tfms = [\n",
    "        crop_bg_pil,\n",
    "        xy_tensor,\n",
    "        tfm_x_wrapper(normalize)\n",
    "    ]\n",
    "    val_dataset = MatchedFilesDataset(val_x, val_y, val_tfms, path='')\n",
    "    if val_bs is None: val_bs = bs\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=val_bs, shuffle=False,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "\n",
    "    train_loader = DataPrefetcher(train_loader)\n",
    "    val_loader = DataPrefetcher(val_loader)\n",
    "    \n",
    "    data = ModelData(data_path, train_loader, val_loader)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(x):\n",
    "    x_np = x.cpu().numpy()\n",
    "    x_np = np.rollaxis(x_np, 0, 3)\n",
    "    mean=np.array([0.485, 0.456, 0.406])\n",
    "    std=np.array([0.229, 0.224, 0.225])\n",
    "    x_np = x_np*std+mean\n",
    "    return x_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-net (ish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg11_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg11(pre): return children(vgg11_bn(pre))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_meta = {\n",
    "    resnet18:[8,6], resnet34:[8,6], resnet50:[8,6], resnet101:[8,6], resnet152:[8,6],\n",
    "    vgg11:[0,13], vgg16:[0,22], vgg19:[0,22],\n",
    "    resnext50:[8,6], resnext101:[8,6], resnext101_64:[8,6],\n",
    "    wrn:[8,6], inceptionresnet_2:[-2,9], inception_4:[-1,9],\n",
    "    dn121:[0,7], dn161:[0,7], dn169:[0,7], dn201:[0,7],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base(f):\n",
    "    cut,lr_cut = model_meta[f]\n",
    "    layers = cut_model(f(True), cut)\n",
    "    return nn.Sequential(*layers), lr_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = output\n",
    "    def remove(self): self.hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, up_in, x_in, n_out):\n",
    "        super().__init__()\n",
    "        up_out = x_out = n_out//2\n",
    "        self.x_conv  = nn.Conv2d(x_in,  x_out,  1)\n",
    "        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(n_out)\n",
    "        \n",
    "    def forward(self, up_p, x_p):\n",
    "        up_p = self.tr_conv(up_p)\n",
    "        x_p = self.x_conv(x_p)\n",
    "        cat_p = torch.cat([up_p,x_p], dim=1)\n",
    "        return self.bn(F.relu(cat_p, inplace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet11Mini(nn.Module):\n",
    "    def __init__(self, out=3, f=vgg11):\n",
    "        super().__init__()\n",
    "        m_base, lr_cut = get_base(f)\n",
    "        self.rn = m_base[0]\n",
    "        self.lr_cut = lr_cut\n",
    "        self.sfs = [SaveFeatures(self.rn[i]) for i in [2,6,13,20,27]]\n",
    "        self.up0 = UnetBlock(512,512,256)\n",
    "        self.up1 = UnetBlock(256,512,256)\n",
    "        self.up2 = UnetBlock(256,256,256)\n",
    "        self.up3 = UnetBlock(256,128,128)\n",
    "        self.up4 = UnetBlock(128,64,64)\n",
    "        self.up5  = nn.Conv2d(64,out,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.rn(x))\n",
    "        x = self.up0(x, self.sfs[4].features)\n",
    "        x = self.up1(x, self.sfs[3].features)\n",
    "        x = self.up2(x, self.sfs[2].features)\n",
    "        x = self.up3(x, self.sfs[1].features)\n",
    "        x = self.up4(x, self.sfs[0].features)\n",
    "        x = self.up5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet34Mod(nn.Module):\n",
    "    def __init__(self, out=3, f=resnet34):\n",
    "        super().__init__()\n",
    "        m_base, lr_cut = get_base(f)\n",
    "        self.rn = m_base\n",
    "        self.lr_cut = lr_cut\n",
    "        self.sfs = [SaveFeatures(self.rn[i]) for i in [2,4,5,6]]\n",
    "        self.up1 = UnetBlock(512,256,256)\n",
    "        self.up2 = UnetBlock(256,128,256)\n",
    "        self.up3 = UnetBlock(256,64,128)\n",
    "        self.up4 = UnetBlock(128,64,64)\n",
    "        self.up5 = UnetBlock(64,32,32)\n",
    "        self.up6 = nn.ConvTranspose2d(32, out, 1)\n",
    "        self.x_skip = nn.Sequential(\n",
    "            nn.Conv2d(out,32,1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x_skip = self.x_skip(x)\n",
    "        x = self.rn(x)\n",
    "        x = self.up1(x, self.sfs[3].features)\n",
    "        x = self.up2(x, self.sfs[2].features)\n",
    "        x = self.up3(x, self.sfs[1].features)\n",
    "        x = self.up4(x, self.sfs[0].features)\n",
    "        x = self.up5(x, x_skip)\n",
    "        x = self.up6(x)\n",
    "        return torch.squeeze(x)\n",
    "    \n",
    "    def close(self):\n",
    "        for sf in self.sfs: sf.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetModel():\n",
    "    def __init__(self,model,name='unet'):\n",
    "        self.model,self.name = model,name\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        if isinstance(self.model, FP16):\n",
    "            model = self.model.module\n",
    "        else:\n",
    "            model = self.model\n",
    "        lgs = list(split_by_idxs(children(model.rn), [model.lr_cut]))\n",
    "        return lgs + [children(model)[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carce_f_p_r(pred, targs):\n",
    "    _,idx = torch.max(pred, 1)\n",
    "    return fbeta_score(idx==1, targs[:,:,:]==1, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdce_f(pred, targs):\n",
    "    _,idx = torch.max(pred, 1)\n",
    "    f,p,r = fbeta_score(idx==2, targs[:,:,:]==2, beta=0.5)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carsig_f_p_r(pred, targs):\n",
    "    p2 = F.sigmoid(pred)\n",
    "    return fbeta_score(p2[:,0,:,:], targs[:,0,:,:], beta=2, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdsig_f(pred, targs):\n",
    "    p2 = F.sigmoid(pred)\n",
    "    f,p,r = fbeta_score(p2[:,1,:,:], targs[:,1,:,:], beta=0.5, threshold=0.5)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def car_f_p_r(pred, targs):\n",
    "    _,idx = torch.max(pred, 1)\n",
    "    return fbeta_score(idx==1, targs[:,1,:,:], beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rd_f(pred, targs):\n",
    "    _,idx = torch.max(pred, 1)\n",
    "    f,p,r = fbeta_score(idx==2, targs[:,2,:,:], beta=0.5)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbeta_score(y_pred, y_true, beta, threshold=None, eps=1e-9):\n",
    "    beta2 = beta**2\n",
    "\n",
    "    if threshold:\n",
    "        y_pred = torch.ge(y_pred.float(), threshold).float()\n",
    "    else:\n",
    "        y_pred = y_pred.float()\n",
    "    y_true = y_true.float()\n",
    "\n",
    "    true_positive = (y_pred * y_true).sum()\n",
    "    precision = true_positive/(y_pred.sum()+(eps))\n",
    "    recall = true_positive/(y_true.sum()+eps)\n",
    "    \n",
    "    fb = (precision*recall)/(precision*beta2 + recall + eps)*(1+beta2)\n",
    "    \n",
    "    return fb, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_acc_sig(pred, targs):\n",
    "    p2 = F.sigmoid(pred)\n",
    "    return ((p2>0.5).long() == targs).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_acc_ce(preds, targs):\n",
    "    mx,idx = torch.max(preds, 1)\n",
    "    return (idx == targs).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_acc(pred, targs):\n",
    "    _,idx = torch.max(pred, 1)\n",
    "    _,t_idx = torch.max(targs,1)\n",
    "    return (idx == t_idx).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff_weight(pred, target, weight):\n",
    "    smooth = 1.\n",
    "    num,c,h,w = pred.shape\n",
    "    m1 = pred.view(num, c, -1)  # Flatten\n",
    "    m2 = target.view(num, c, -1)  # Flatten\n",
    "    intersection = (m1 * m2)\n",
    "    w = V(weight.view(1,-1,1))\n",
    "    i_w = (w*intersection).sum()\n",
    "    m1_w = (w*m1).sum()\n",
    "    m2_w = (w*m2).sum()\n",
    "    return (2. * i_w + smooth) / (m1_w + m2_w + smooth)\n",
    "\n",
    "def dice_coeff(pred, target):\n",
    "    smooth = 1.\n",
    "    num,c,h,w = pred.shape\n",
    "    m1 = pred.view(num, c, -1)  # Flatten\n",
    "    m2 = target.view(num, c, -1)  # Flatten\n",
    "    intersection = (m1 * m2).sum()\n",
    "    return (2. * intersection + smooth) / (m1.sum() + m2.sum() + smooth)\n",
    "\n",
    "\n",
    "class SoftDiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True, softmax=True):\n",
    "        super(SoftDiceLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.softmax = softmax\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = F.softmax(logits) if self.softmax else F.sigmoid(logits)\n",
    "        num = targets.size(0)  # Number of batches\n",
    "        targets = torch.cat(((targets==0).unsqueeze(1), (targets==1).unsqueeze(1), (targets==2).unsqueeze(1)), dim=1).float()\n",
    "        if isinstance(logits.data, torch.cuda.HalfTensor):\n",
    "            targets = targets.half()\n",
    "        else:\n",
    "            targets = targets.float()\n",
    "        if self.weight is not None:\n",
    "            score = dice_coeff_weight(probs, targets, self.weight)\n",
    "        else:\n",
    "            score = dice_coeff(probs, targets)\n",
    "        score = 1 - score.sum() / num\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learner(md, m_fn=Unet11Mini, weights=[1,200,2], half=False, softmax=True, dice=False):\n",
    "    out_sz = 3 if softmax else 2\n",
    "    m = to_gpu(m_fn(out_sz))\n",
    "    models = UnetModel(m)\n",
    "    learn = ConvLearner(md, models)\n",
    "    learn.opt_fn=optim.Adam\n",
    "    class_weights = torch.cuda.FloatTensor(weights)\n",
    "    if half:\n",
    "        class_weights = class_weights.half()\n",
    "        learn.half()\n",
    "        \n",
    "    if dice: learn.crit=SoftDiceLoss(weight=class_weights, softmax=softmax)\n",
    "    else: learn.crit=nn.CrossEntropyLoss(weight=class_weights)\n",
    "    \n",
    "    if softmax: learn.metrics = [new_acc_ce, rdce_f, carce_f_p_r]\n",
    "    else: learn.metrics = [new_acc_sig, rdsig_f, carsig_f_p_r]\n",
    "    # learn.metrics=[new_acc, rd_f, car_f_p_r]\n",
    "    \n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Labels: 400\n",
      "Val x:400, y:400\n",
      "Trn x:10880, y:10880\n",
      "All x:10880\n"
     ]
    }
   ],
   "source": [
    "ext = '-300'\n",
    "sz=192\n",
    "bs=64\n",
    "random_crop=True\n",
    "md = torch_loader(ext, PATH, bs, sz, workers, random_crop, pseudo_label, val_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Unet11Mini()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.rn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(md, weights=[1,6,2], softmax=True)\n",
    "# learn.load(f'256urn-40-unet11-mini-softmax-tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d7e9e27688463a8318298bbe78feec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 149/170 [00:26<00:03,  5.61it/s, loss=2.24] "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=5e-2\n",
    "wd=1e-7\n",
    "\n",
    "lrs = np.array([lr/80,lr/10,lr])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea6b6b7cacb49ad85879637f776f176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   new_acc_ce rdce_f     carce_f_p_r \n",
      "    0      0.096004   0.09335    0.979139   0.977114   0.821443   0.720103   0.855077  \n",
      "    1      0.075364   0.090361   0.972371   0.980085   0.780143   0.497367   0.912888  \n",
      "    2      0.066693   0.064372   0.984737   0.988135   0.870611   0.695097   0.930991  \n",
      "    3      0.066896   0.071211   0.986959   0.989522   0.856028   0.82587    0.864591  \n",
      "    4      0.062642   0.076503   0.984923   0.987302   0.85122    0.778274   0.872944  \n",
      "    5      0.061202   0.064056   0.985788   0.990056   0.880026   0.734558   0.928957  \n",
      "    6      0.060444   0.06841    0.986415   0.987958   0.855935   0.774511   0.880055  \n",
      "    7      0.061943   0.071132   0.984703   0.982268   0.858668   0.775061   0.884359  \n",
      "    8      0.059203   0.085391   0.984592   0.986871   0.846794   0.784408   0.865046  \n",
      "    9      0.059143   0.082025   0.982779   0.984583   0.820771   0.69029    0.862911  \n",
      "    10     0.063815   0.077606   0.986095   0.986155   0.836809   0.780368   0.853775  \n",
      "    11     0.064941   0.075204   0.986252   0.989125   0.852466   0.826612   0.859696  \n",
      "    12     0.060065   0.071728   0.985717   0.986564   0.841729   0.735017   0.876627  \n",
      "    13     0.058621   0.074056   0.985828   0.990101   0.864769   0.79121    0.88595   \n",
      "    14     0.060169   0.091316   0.980605   0.985068   0.85695    0.710041   0.905092  \n",
      "    15     0.062267   0.073407   0.984786   0.985236   0.854959   0.757646   0.884653  \n",
      "    16     0.056938   0.073423   0.985146   0.986845   0.861551   0.7992     0.879591  \n",
      "    17     0.05808    0.065442   0.9881     0.987219   0.86252    0.856539   0.864444  \n",
      "    18     0.055639   0.05956    0.986168   0.984551   0.878955   0.789051   0.905337  \n",
      "    19     0.058758   0.057829   0.984986   0.984674   0.868137   0.721266   0.915964  \n",
      "    20     0.056907   0.057971   0.988325   0.989151   0.869309   0.797371   0.890007  \n",
      "    21     0.05371    0.056051   0.987573   0.991045   0.892207   0.773089   0.928392  \n",
      "    22     0.052237   0.054796   0.986779   0.987004   0.885017   0.750594   0.927984  \n",
      "    23     0.056984   0.065131   0.987193   0.988542   0.857037   0.783654   0.879614  \n",
      "    24     0.052353   0.052273   0.989605   0.991906   0.890997   0.816784   0.912137  \n",
      "    25     0.050993   0.054655   0.988561   0.989601   0.890917   0.811397   0.913854  \n",
      "    26     0.051122   0.060634   0.987572   0.990087   0.885198   0.784931   0.915009  \n",
      "    27     0.048544   0.053527   0.989816   0.99289    0.887902   0.813457   0.909115  \n",
      "    28     0.047726   0.047591   0.989908   0.991765   0.8964     0.804452   0.923102  \n",
      "    29     0.046301   0.047649   0.989685   0.991215   0.894555   0.799678   0.92239   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04764939561486244,\n",
       " 0.9896846842765809,\n",
       " 0.9912151885032654,\n",
       " 0.894555253982544,\n",
       " 0.7996777153015137,\n",
       " 0.9223898887634278]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, 1, wds=wd, cycle_len=30,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'300urn-{S_PREFIX}-tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.set_bn_freeze(learn.model.rn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd36e1425ec04178a3e1282dddbe7490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   new_acc_ce rdce_f     carce_f_p_r \n",
      "    0      0.04833    0.05015    0.989503   0.990312   0.896537   0.809499   0.921836  \n",
      "    1      0.047755   0.049072   0.989659   0.990996   0.897432   0.806178   0.924125  \n",
      "    2      0.04757    0.049234   0.9898     0.990974   0.897299   0.812862   0.92172   \n",
      "    3      0.046933   0.048602   0.989708   0.991061   0.898414   0.804579   0.925933  \n",
      "    4      0.046733   0.048302   0.989836   0.991447   0.899279   0.806277   0.926528  \n",
      "    5      0.046848   0.048525   0.990005   0.991278   0.896513   0.814408   0.920149  \n",
      "    6      0.046277   0.047439   0.990036   0.991843   0.900479   0.809366   0.927061  \n",
      "    7      0.046933   0.048338   0.990072   0.991972   0.89899    0.810152   0.924789  \n",
      "    8      0.045886   0.048173   0.990279   0.992012   0.898499   0.817751   0.921662  \n",
      "    9      0.045959   0.047799   0.990221   0.991888   0.899047   0.813274   0.9238    \n",
      "    10     0.045692   0.047948   0.990278   0.992121   0.899856   0.815688   0.924117  \n",
      "    11     0.046031   0.047776   0.990273   0.991943   0.899202   0.814832   0.923511  \n",
      "    12     0.045991   0.046513   0.990209   0.991887   0.902681   0.809106   0.93004   \n",
      "    13     0.045927   0.04756    0.990289   0.992081   0.899908   0.816101   0.924068  \n",
      "    14     0.045488   0.048006   0.99014    0.991289   0.899294   0.814698   0.923692  \n",
      "    15     0.045497   0.047097   0.990413   0.991844   0.900867   0.8183     0.924584  \n",
      "    16     0.045393   0.046676   0.990346   0.991725   0.901845   0.815055   0.926911  \n",
      "    17     0.045635   0.046816   0.990335   0.99182    0.901685   0.815319   0.926634  \n",
      "    18     0.04516    0.046892   0.990296   0.991888   0.901733   0.81336    0.927324  \n",
      "    19     0.045415   0.047321   0.990369   0.992088   0.901076   0.816083   0.92557   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.047320610880851745,\n",
       " 0.9903688097000122,\n",
       " 0.9920884895324708,\n",
       " 0.9010760736465454,\n",
       " 0.8160830712318421,\n",
       " 0.925570170879364]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs/40, 1, wds=wd, cycle_len=20,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'300urn-{S_PREFIX}-rc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Labels: 400\n",
      "Val x:400, y:400\n",
      "Trn x:10880, y:10880\n",
      "All x:10880\n"
     ]
    }
   ],
   "source": [
    "ext = '-300'\n",
    "sz=192\n",
    "bs=64\n",
    "random_crop=False\n",
    "md = torch_loader(ext, PATH, bs, sz, workers, random_crop, pseudo_label, val_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "wd=1e-7\n",
    "\n",
    "lrs = np.array([lr/50,lr/10,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(f'300urn-{S_PREFIX}-rc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "# learn.set_bn_freeze(learn.model.rn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c279845aee4433cad03471eac5711cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   new_acc_ce rdce_f     carce_f_p_r \n",
      "    0      0.045858   0.046527   0.990386   0.992144   0.901871   0.813814   0.927358  \n",
      "    1      0.045499   0.046361   0.990473   0.99211    0.902229   0.816338   0.926993  \n",
      "    2      0.045118   0.047045   0.990377   0.992038   0.900561   0.816371   0.924795  \n",
      "    3      0.045238   0.046694   0.990396   0.99198    0.901187   0.815488   0.925904  \n",
      "    4      0.045646   0.047081   0.990326   0.991958   0.90168    0.814773   0.92679   \n",
      "    5      0.044952   0.046781   0.990453   0.992111   0.901229   0.817462   0.925312  \n",
      "    6      0.045121   0.046563   0.990398   0.991888   0.9015     0.816576   0.925964  \n",
      "    7      0.0455     0.046766   0.990465   0.992198   0.901367   0.817685   0.925417  \n",
      "    8      0.045455   0.046295   0.990411   0.991635   0.901115   0.818094   0.924944  \n",
      "    9      0.045424   0.047416   0.99042    0.992117   0.900005   0.818635   0.923337  \n",
      "    10     0.046234   0.046389   0.990484   0.992043   0.901735   0.81748    0.925969  \n",
      "    11     0.045854   0.046454   0.990456   0.991866   0.901087   0.817381   0.925146  \n",
      "    12     0.045262   0.046848   0.990449   0.992034   0.901032   0.818078   0.924851  \n",
      "    13     0.04515    0.046468   0.990401   0.99199    0.901866   0.815011   0.926952  \n",
      "    14     0.045004   0.047375   0.990348   0.991941   0.900296   0.81754    0.924067  \n",
      "    15     0.045456   0.04664    0.99038    0.99198    0.902278   0.814339   0.927732  \n",
      "    16     0.04475    0.046632   0.990359   0.992018   0.90205    0.813567   0.92769   \n",
      "    17     0.045168   0.046344   0.990369   0.991828   0.901709   0.814434   0.926936  \n",
      "    18     0.044895   0.046468   0.99043    0.992153   0.902062   0.815117   0.927179  \n",
      "    19     0.04525    0.04641    0.990441   0.992006   0.901744   0.815894   0.926505  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04641000270843506,\n",
       " 0.9904410409927368,\n",
       " 0.9920058917999267,\n",
       " 0.9017435503005982,\n",
       " 0.8158935332298278,\n",
       " 0.9265050435066223]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs/80, 1, wds=wd, cycle_len=20,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'300urn-{S_PREFIX}-nocrop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = get_learner(md, weights=[1,6,1], softmax=True, dice=True)\n",
    "# learn.load(f'300urn-{S_PREFIX}-rc')\n",
    "\n",
    "# learn.fit(lrs/60, 1, wds=wd, cycle_len=10,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Labels: 400\n",
      "Val x:400, y:400\n",
      "Trn x:10880, y:10880\n",
      "All x:10880\n"
     ]
    }
   ],
   "source": [
    "ext = ''\n",
    "sz=320\n",
    "bs=32\n",
    "random_crop=True\n",
    "md = torch_loader(ext, PATH, bs, sz, workers, random_crop, pseudo_label, val_folder, val_bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(md, weights=[1,6,1], softmax=True, dice=False)\n",
    "learn.load(f'300urn-{S_PREFIX}-rc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-2\n",
    "wd=1e-7\n",
    "\n",
    "lrs = np.array([lr/100,lr/10,lr])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.set_bn_freeze(learn.model.rn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f84f2e198f45da9bd1d6260766ec1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   new_acc_ce rdce_f     carce_f_p_r \n",
      "    0      0.049726   0.144055   0.966211   0.959904   0.806588   0.660844   0.864498  \n",
      "    1      0.048467   0.114893   0.971116   0.969913   0.806269   0.615117   0.888197  \n",
      "    2      0.04632    0.111767   0.975526   0.969559   0.81942    0.668846   0.878311  \n",
      "    3      0.045766   0.105717   0.977156   0.974863   0.812394   0.642744   0.881221  \n",
      "    4      0.044151   0.091566   0.979561   0.981112   0.823166   0.639713   0.898401  \n",
      "    5      0.043795   0.095885   0.979168   0.984012   0.81795    0.635544   0.893858  \n",
      "    6      0.041897   0.103706   0.980399   0.979461   0.813368   0.657094   0.87523   \n",
      "    7      0.042073   0.096937   0.980472   0.981958   0.818796   0.64372    0.890015  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09693678081035614,\n",
       " 0.9804724264144897,\n",
       " 0.9819580626487732,\n",
       " 0.8187955474853515,\n",
       " 0.643720309138298,\n",
       " 0.8900147128105164]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=8,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'600urn-{S_PREFIX}-320')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Labels: 400\n",
      "Val x:400, y:400\n",
      "Trn x:10880, y:10880\n",
      "All x:10880\n"
     ]
    }
   ],
   "source": [
    "ext = ''\n",
    "sz=384\n",
    "bs=24\n",
    "random_crop=True\n",
    "md = torch_loader(ext, PATH, bs, sz, workers, random_crop, pseudo_label, val_folder, val_bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(md, weights=[1,6,1], softmax=True, dice=False)\n",
    "learn.load(f'600urn-{S_PREFIX}-320')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "wd=1e-7\n",
    "\n",
    "lrs = np.array([lr/100,lr/10,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.set_bn_freeze(learn.model.rn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa14c3bca06f4e71b636ad9e1f0d5fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   new_acc_ce rdce_f     carce_f_p_r \n",
      "    0      0.037408   0.074222   0.984106   0.983053   0.863756   0.748513   0.902073  \n",
      "    1      0.036542   0.073611   0.983616   0.982054   0.865665   0.749924   0.903642  \n",
      "    2      0.035858   0.068502   0.985372   0.983713   0.869941   0.767936   0.902185  \n",
      "    3      0.033802   0.069879   0.98465    0.98125    0.872788   0.765963   0.906763  \n",
      "    4      0.034993   0.068896   0.984855   0.980792   0.873563   0.762292   0.909306  \n",
      "    5      0.033734   0.066109   0.985731   0.984279   0.873255   0.761452   0.908966  \n",
      "    6      0.034588   0.063372   0.984958   0.984088   0.867123   0.717302   0.919528  \n",
      "    7      0.033411   0.06407    0.985889   0.984713   0.873135   0.754782   0.911627  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06406990803778172,\n",
       " 0.9858893942832947,\n",
       " 0.9847134971618652,\n",
       " 0.8731347668170929,\n",
       " 0.7547824084758759,\n",
       " 0.9116272282600403]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=8,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'600urn-{S_PREFIX}-384')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nocrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Labels: 400\n",
      "Val x:400, y:400\n",
      "Trn x:10880, y:10880\n",
      "All x:10880\n"
     ]
    }
   ],
   "source": [
    "ext = ''\n",
    "sz=384\n",
    "bs=10\n",
    "random_crop=False\n",
    "md = torch_loader(ext, PATH, bs, sz, workers, random_crop, pseudo_label, val_folder, val_bs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(md, weights=[1,6,1], softmax=True)\n",
    "learn.load(f'600urn-{S_PREFIX}-384')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "wd=1e-7\n",
    "\n",
    "lrs = np.array([lr/100,lr/10,lr])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "# learn.bn_freeze(True)\n",
    "learn.set_bn_freeze(learn.model.rn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57b02a3e9fd49198d2222a3638def54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   new_acc_ce rdce_f     carce_f_p_r \n",
      "    0      0.019354   0.05315    0.987901   0.988664   0.865779   0.755049   0.901924  \n",
      "    1      0.015589   0.050898   0.987545   0.989378   0.865618   0.740412   0.908001  \n",
      "    2      0.015276   0.050835   0.988384   0.988834   0.868634   0.767228   0.902089  \n",
      "    3      0.015398   0.05059    0.988026   0.989936   0.868582   0.782364   0.898059  \n",
      "    4      0.012434   0.050843   0.988196   0.989178   0.873788   0.774273   0.906412  \n",
      "    5      0.012499   0.048416   0.98887    0.989265   0.877941   0.785928   0.907503  \n",
      "    6      0.011603   0.049167   0.989436   0.990114   0.877475   0.809242   0.899455  \n",
      "    7      0.011888   0.047989   0.989149   0.989973   0.879205   0.789414   0.908457  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.047988875657320025,\n",
       " 0.9891493153572083,\n",
       " 0.9899731516838074,\n",
       " 0.8792047075927257,\n",
       " 0.789413645863533,\n",
       " 0.9084567312896251]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=8,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'600urn-{S_PREFIX}-384-nocrop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs/50, 1, wds=wd, cycle_len=6,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'600urn-{S_PREFIX}-384-nocrop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = ''\n",
    "sz=384\n",
    "bs=10\n",
    "random_crop=False\n",
    "md = torch_loader(ext, PATH, bs, sz, workers, random_crop, pseudo_label, val_folder, val_bs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(md, m_fn=Unet34Mod, weights=[1,7,1], softmax=True)\n",
    "learn.load(f'600urn-{S_PREFIX}-384-nocrop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-4\n",
    "wd=1e-7\n",
    "\n",
    "lrs = np.array([lr/200,lr/20,lr])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "# learn.bn_freeze(True)\n",
    "learn.set_bn_freeze(learn.model.rn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=6,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'600urn-{S_PREFIX}-384-nocrop-w8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(f'600urn-{S_PREFIX}-384-nocrop-w8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "# learn.bn_freeze(True)\n",
    "learn.set_bn_freeze(learn.model.rn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs/40, 1, wds=wd, cycle_len=3,use_clr=(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'600urn-{S_PREFIX}-384-nocrop-w8-tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "86px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
